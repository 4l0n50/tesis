\newcommand{\setsize}{t}

In this section we show that for any subset \(S\subset\Z_q\) such that \(|S|=\poly(\lambda)\) one can construct an aZKSMP whose size is \(\Theta(\log|S|)\). We then show how to translate this results to fixed subsets \(S\subset\mathbb{G}_s\), \(s\in\{1,2\}\), i.e~when the proof sytem's CRS is fixed to a specific set \(S\).

On Section~\ref{sec:aZKSMP} we built a proof system for the case \(S=[0,2^n-1]\) with the same proof size, however, when \(S\) is not of this form, the proof size was \(\Theta(|S|)\). When \(S\) is a fixed subset of \(\GG_s\) the proof system from Section~\ref{sec:aZKSMP} also requires proofs of size \(\Theta(|S|)\).

Our proof bears some similarities with the work of Groth and Kohlweiss \cite{EC:GroKoh15} -- both allows to construct proofs of membership in a set of logarithmic size using the binary encoding of the element index -- but they are in general incomparable. Indeed, Groth and Kohlweiss's construction is on a different setting (interactive, without pairings) and does not support aggregation of many proofs.

\subsection{Intuition}

For simplicity, we will restrict to the case \(S=\{s_1,\ldots,s_\setsize \}\subset\Z_q\) without aggregation, that is, there is a single commitment \([\vecb{c}]_1=\GS.\Com_{ck}(x;r)\) and we want to show that \(x=s_\alpha\), for some \(\alpha\in[\setsize ]\). Then we will show how to aggregate many proofs.

The (non-aggregated) proof from Section~\ref{sec:aZKSMP} essentially codifies the position \(\alpha\) as a weight 1 binary vector \(\vecb{b}\) of size \(\setsize \) such that \(x=\sum_{i\in[\setsize ]}b_is_i\) and
\(b_i=1\) if \(i=\alpha\) and \(0\) if not.\footnote{The case \(S\subset\Z_q\) is not really discussed in Section~\ref{sec:aZKSMP}, but it is straightforward that the same techniques from the case \(S\subset\GG_s\) apply.} A step further in efficiency was given by Chandran et al.~\cite{ICALP:ChaGroSah07} (already discussed in Section~\ref{sec:bits-applications}), there the position \(\alpha\) is codified as two weight 1 binary vectors \(\vecb{b}\) and \(\vecb{b}'\) of size \(\sqrt{\setsize }\) such that
\[
\begin{pmatrix}
x_1\\\vdots\\x_{\sqrt{\setsize }}
\end{pmatrix}
=\sum_{i=1}^{\sqrt{\setsize }}b_i
\begin{pmatrix}
s_{(i-1)\sqrt{\setsize }+1}\\\vdots\\s_{(i-1)\sqrt{\setsize }+\sqrt{\setsize }}
\end{pmatrix},
\text{ } x=\sum_{i=1}^{\sqrt{\setsize }}b'_ix_i,\]
and \(b_i=1\) iff \(i=i_\alpha\) and \(b'_j=1\) iff \(j=j_\alpha\), where \(\alpha=(i_\alpha-1)\sqrt{\setsize }+j_\alpha\). Since \(\sqrt{\setsize }\) new variables are added (variables \(x_1,\ldots,x_{\sqrt{\setsize }}\)), the proof must contain \(\sqrt{\setsize }\) new commitments to this variables. However, this does not not affect the asymptotic size of the proof which is \(\Theta(\sqrt{\setsize })\) anyway.


Let $m:=\log \setsize$.\footnote{ W.l.o.g.~we assume that \(\log \setsize \in\mathbb{N}\), because we can always work with the (multi-)set \(S'=S\biguplus_{i=1}^{\setsize -2^{\lceil \log \setsize  \rceil}}\{s_{\setsize} \}\).} The natural next step is to codify \(\alpha\) as \(m\) weight 1 binary vectors of size 2 (note that a weight 1 binary vectors of size 2 can be always written as \((1-b,b)\), \(b\in\bits\) ) such that
\begin{align}
&\begin{pmatrix}
x_{i,1}\\\vdots\\x_{i,\setsize /{2^i}}
\end{pmatrix}
=
(1-b_i)
\begin{pmatrix}
x_{i-1,1}\\\vdots\\x_{i-1,\setsize /{2^i}}
\end{pmatrix}
+
b_i
\begin{pmatrix}
x_{i-1, \setsize /{2^i}+1}\\\vdots\\x_{i-1, \setsize /{2^{i-1}}}
\end{pmatrix}
\text{ if } 1 \leq  i \leq m,\label{eq-log-2}\\
&
x= x_{m,1}\label{eq-log-3},
\end{align}
where \(x_{0,i}:=s_i\), \(i\in[\setsize ]\), and \(\alpha=\sum_{i=1}^{m}b_i2^{m-i}+1\). Note that we have added the additional variables \(x_{i,j}\), \(i\in[m]\) and \(j\in[\setsize /2^i]\).

Similarly as in Chandran et al.'s proof, for each new variable a new commitment must be added to the proof. But, in contrast with Chandran et al.'s proof, in this case the additional commitments do increase the asymptotic size of the proof since \(\setsize /2+\setsize /2^2+\ldots+1=\Theta(\setsize )\) new variables have been added.

One can reduce the total size of the commitments using the length reducing Multi-Pedersen commitments from Section~\ref{sec:ext-mp}. In this way, the prover computes commitments to the variables $x_{i,j}$, $i\in[n],j\in[\setsize/2^i]$ as follows
\begin{align*}
&[\vecb{c}_1]_1=\MP.\Com_{ck_1}((x_{1,1},\ldots,x_{1,\setsize /2})^\top;r_1),\\
&[\vecb{c}_2]_1=\MP.\Com_{ck_2}((x_{2,1},\ldots,x_{2,\setsize /2^2})^\top;r_2),\\
&\quad\vdots\\
&[\vecb{c}_{m}]_1=\MP.\Com_{ck_{m}}((x_{m-1,1},x_{m-1,2})^\top;r_{m-1}),
\end{align*}
for random $r_1,\ldots,r_{m-1}\in\Z_q$. 

To show that the committed variables satisfy equation (\ref{eq-log-2}) is necessary multiply variables \(x_{i-1,1},\ldots,x_{i-1,\setsize /2^i}\) by \(1-b_i\) and multiply variables \(x_{i-1,\setsize /2^i+1},\ldots,\allowbreak x_{i-1,\setsize /2^{i-1}}\) by \(b_i\). However, all the variables $x_{i-1,1},\ldots x_{i-1,\setsize /2^{i-1}}$ are on a single commitment which we can not multiply by himself.
The problem is thus how to extract from \([\vecb{c}_{i-1}]_1\) two additional commitments \([\vecb{c}_{i-1,1}]_1\) and \([\vecb{c}_{i-1,2}]\) to \(x_{i-1,1},\ldots,x_{i-1,\setsize /2^i}\) and to \(x_{i-1,\setsize /2^i+1},\ldots,x_{i-1,\setsize /2^{i-1}}\), respectively, in order to prove that equation (\ref{eq-log-2}) is satisfied.

For \(i\in[m]\), let \(ck_i:=([\matr{G}_i]_1,\allowbreak[\vecb{g}_{i,\setsize /2^i+1}]_1)\in\GG_1^{2\times{\setsize /2^i+1}}\) a commitment key of the MP commitment scheme and let
\begin{align*}
&\matr{G}_{i,1}:=
\begin{pmatrix}
    \vecb{g}_{i,1}&\cdots&\vecb{g}_{i,2^{i+1}}
\end{pmatrix},
&\matr{G}_{i,2}:=
\begin{pmatrix}
    \vecb{g}_{i,\setsize /2^{i+1}+1}&\cdots&\vecb{g}_{i,\setsize /2^i}
\end{pmatrix}\\
&\matr{G}_i:=\matr{G}_{i,1}||\matr{G}_{i,2}
\end{align*}
Our solution splits \([\vecb{c}_{i-1}]_1\) in two different commitments to the first and last halves of \((x_{i-1,1},\ldots,x_{i-1,2^{i-1}})\) and proves that the following linear system is satisfied
{\begin{align}
&\begin{pmatrix}
\vecb{c}_{i-1}\\
\vecb{c}_{i,1}\\
\vecb{c}_{i,2}
\end{pmatrix}
=
&\left(\begin{array}{cc|ccc}
\matr{G}_{i-1,1}         & \matr{G}_{i-1,2}         & \vecb{g}_{i-1,\setsize /2^{i-1}+1} & \vecb{0}             & \vecb{0}\\
\matr{G}_{i}             & \matr{0}_{2\times \setsize /2^i} & \vecb{0}                   & \vecb{g}_{i,\setsize /2^i+1} & \vecb{0} \\
\matr{0}_{2\times \setsize /2^i} & \matr{G}_{i}             & \vecb{0}                   & \vecb{0}             & \vecb{g}_{i,\setsize /2^i+1}
\end{array}\right)
\vecb{w},\label{eq-log-split}
\end{align}}%
for some \(\vecb{w}\in\Z_q^{\setsize /2^{i-1}+3}\).
Intuitively, \(\vecb{w}\) should be equal to \((x_{i-1,1},\ldots,x_{i-1,\setsize /2^{i-1}},\allowbreak r_{i-1},r_{i-1,1},r_{i-1,2})\) and thus 
\begin{align*}
&[\vecb{c}_{i,1}]_1=\MP.\Com_{ck_i}(\allowbreak(x_{i-1,1},\ldots,x_{i-1,\setsize /2^{i}})^\top;r_{i-1,1})\text{ and }\\
&[\vecb{c}_{i,2}]_1=\MP.\Com_{ck_i}((x_{i-1,2^i+1},\ldots, x_{i-1,\setsize /2^{i-1}})^\top;r_{i-1,2}).
\end{align*}
However, since Multi-Pedersen commitments have multiple openings it might be the case that the satisfying witness of the proof is different from \((x_{i-1,1},\ldots,\allowbreak x_{i-1,\setsize /2^{i-1}},r_{i-1},r_{i-1,1},r_{i-1,2})\) and thus the intuitive reasoning is invalid.

Despite this flawed reasoning, we will show that the proof system is still sound. But first lets see how the proof system goes in a little more detail.

\subsubsection{The Scheme}
Given \([\vecb{c}]_1=\GS.\Com_{ck}(s_\alpha;r)\), \(\alpha=\sum_{i=1}^{m}b_i2^{m-i}+1\), the prover computes
\begin{align*}
&[\vecb{c}_i]_1:=\MP.\Com_{ck_i}((x_{i,1},\ldots,x_{i,\setsize /2^i})^\top;r_i) \text{ for } i \in[m], \text{ and}\\
&[\vecb{c}_{i,1}]_1:=\MP.\Com_{ck_i}((x_{i,1},\ldots,x_{i,\setsize /2^{i+1}})^\top;r_{i,1}),\\
&[\vecb{c}_{i,2}]_1:=\MP.\Com_{ck_i}((x_{i,2^{i+1}+1},\ldots, x_{i,\setsize /2^i})^\top;r_{i,2})\text{ for }1 < i \leq m,
\end{align*}
where \(r_i,r_{i,1},r_{i,2}\gets\Z_q\) and the variables \(x_{i,j}\) are the ones defined in equation (\ref{eq-log-2}). Then, the prover shows that
\([\vecb{c}_1]_1\) opens to the first or second half (depending on the value of \(b_1\)) of \((s_1,\ldots,s_\setsize )\), that \([\vecb{c}_{2,1}]_1\) and \([\vecb{c}_{2,2}]\) opens to the first and second half, respectively, of an opening of \([\vecb{c}_{1}]\), and so on. This statement can be proven with a GS proof of
 the satisfiability of
\begin{align}
&[\vecb{c}_1]_1-\left((1-b_1)\sum_{i=1}^{\setsize /2}s_i[\vecb{g}_{1,i}]_1 + b_1\sum_{i=1}^{\setsize /2} s_{\setsize /2+i}[\vecb{g}_{1,i}]_1\right) = y_1[\vecb{g}_{1,\setsize /2+1}]_1 \label{eq-log-4}\\
&[\vecb{c}_i]_1-\left((1-b_i)[\vecb{c}_{i,1}]_1+b_i[\vecb{c}_{i,2}]_1\right) = y_i[\vecb{g}_{i,\setsize /2+1}]_1, \text{ for } 1 < i \leq m,  \label{eq-log-5}
\end{align}
a QA-NIZK proof that
\begin{equation}
[\vecb{c}]_1\text{ and }[\vecb{c}_m]_1\text{ open to the same value}, \label{eq-log-6}
\end{equation}
and also a QA-NIZK proof that equation (\ref{eq-log-split}) is satisfied for each \(1<i\leq m\).

The verifier accepts the proof iff the proofs for (\ref{eq-log-split}), (\ref{eq-log-4}), (\ref{eq-log-5}), and (\ref{eq-log-6}) are valid.

\subsubsection{Soundness}
We assume \(b_1,\ldots,b_m\) are bits. Note that this can be proven (with perfect soundness) with a GS proof of size \(O(\log \setsize )\) or using the more efficient proofs of Section~\ref{sec:bits} (with computational soundness).

Suppose that an adversary against soundness outputs GS commitments to \(b_1,\ldots,b_{m}\in\bits\), outputs commitments \([\vecb{c}_i]_1\) and \([\vecb{c}_{i,j}]_1\), \(1< i\leq m\) and \(j\in\{1,2\}\), GS proofs of the satisfiability of equations (\ref{eq-log-4}) and (\ref{eq-log-5}), and QA-NIZK proofs of (\ref{eq-log-5}) and (\ref{eq-log-split}) for each \(1<i<m\).

In the next argument it will be useful to use the notation \((b_1\cdots b_m):=\sum_{i=1}^{m}b_i2^{m-i}+1\) and we define \((b_i\cdots b_m)=1\) if \(i>m\).
In the security reduction we will choose an index \((b'_2\ldots b'_m)\gets[\setsize /2]\) and will choose the commitment key \(ck_i\), \(i\in[m]\) from the distributions \(\distlin_1^{\setsize /2^i,(b'_{i+1}\cdots b'_m)}\) defined in Section \ref{sec:mddh}.\footnote{If \((b'_1\ldots b'_m)\) is the binary representation of an integer in \([\setsize /2]\), then \(b'_1=0\) and thus we can always discard \(b'_1\).}  If $ck_i$ is chosen from $\distlin_1^{\setsize /2^i,(b'_{i+1}\cdots b'_m)}$ is guarantied that, for all \(i\in[m]\), \(\vecb{g}_{i,(b'_{i+1}\ldots b'_m)}\) is linearly independent from all the other vectors in the commitment key \(ck_i\). The reduction will abort if \((b'_2\cdots b'_m)\neq\sum_{i=2}^{m} b_i2^{m-i}+1\), which happens with probability \(2/\setsize \). From now onwards we assume that we are in the case \((b'_2,\ldots,b'_m)=\sum_{i=2}^{m} b_i2^{m-i}+1\) and therefore, our reduction will have a security loss factor of \(2/\setsize \).

We prove by induction on \(i\) that \(\vecb{c}_i=s_{(b_1\cdots b_m)}\vecb{g}_{i,(b_{i+1}\cdots b_m)}+\tilde{r}_i\vecb{g}_{i,\setsize /2^i+1}\). If this is the case, the soundness of proof (\ref{eq-log-6}) together with the fact that \(ck_m\) is perfectly binding implies that \(x=x_{m,1}=s_{(b_1\cdots b_m)}\in S\) and we are ready. In the base case, equation (\ref{eq-log-4}) and the fact that \(\vecb{g}_{1,j}\in\Span(\vecb{g}_{1,\setsize /2+1})\) if \(j\neq (b_2\cdots b_m)\) implies that 
\begin{align*}
\vecb{c}_1 &= (1-b_1)s_{(0b_2\cdots b_m)} \vecb{g}_{1,(b_2\cdots b_m)}+b_1s_{(1b_2\cdots b_m)}\vecb{g}_{1,(b_2\cdots b_m)}+\tilde{r}_1\vecb{g}_{1,\setsize /2+1}\\
&=s_{(b_1\cdots b_m)}\vecb{g}_{1,(b_2\cdots b_m)}+\tilde{r}_1\vecb{g}_{1,\setsize /2+1},
\end{align*} for some \(\tilde{r}_1\in\Z_q\).

In the inductive case we assume that \(\vecb{c}_{i-1}=s_{(b_1\cdots b_m)}\vecb{g}_{i-1,(b_i\cdots b_m)}+\tilde{r}_{i-1}\vecb{g}_{i-1,\setsize /2^{i-1}+1}\). Since \(\vecb{g}_{i-1,(b_i\cdots b_m)}\) is linearly independent from the rest of vectors in \(ck_{i-1}\), any solution to equation (\ref{eq-log-split}) is equal to \(s_{(b_1\cdots b_m)}\) at position \((b_i\cdots b_m)\). An analysis of the two cases \(b_i=0\) or \(b_i=1\) shows that \(\vecb{c}_{i,b_i+1}=s_{(b_1\cdots b_m)}\vecb{g}_{i,(b_{i+1}\cdots b_m)}+\tilde{r}_{i,b_i+1}\vecb{g}_{i,2^i+1}\). Finally, equation (\ref{eq-log-5}) implies that \(\vecb{c}_i=s_{(b_1\cdots b_m)}\vecb{g}_{i,(b_{i+1}\cdots b_m)}+\tilde{r}_i\vecb{g}_{i,\setsize /2^i+1}\) for some \(\tilde{r}_{i}\in\Z_q\).

\subsection{The Aggregated Case}
Let $\setsize:=|S|$ and \(m:=\log \setsize \). The statement is now \([\grkb{\zeta}_1]=\GS.\Com_{ck}(x_1;r_1),\ldots,\allowbreak[\grkb{\zeta}_n]_1=\GS.\Com_{ck}(x_n;r_n)\), for some $n\in\mathbb{N}$, and the prover wants to show that \(x_i=s_{\alpha_i}\), for all \(i\in[n]\) and \(\alpha_i=\sum_{j=1}^m b_{i,j}2^m+1\), for some $b_{i,1},\ldots,b_{i,m}\in\bits$. We need reformulate equations (\ref{eq-log-2}) and (\ref{eq-log-3}) to take in count new variables. For \(\ell\in [m],j\in[n]\), define
\begin{align*}
&\vecb{x}_j^\ell:=
\begin{pmatrix}
\vecb{x}^\ell_{1,j}\\
\hline
\vecb{x}^\ell_{2,j}
\end{pmatrix}
:=
\begin{pmatrix}
x^\ell_{1,j}\\\vdots\\x^\ell_{\setsize ^{\ell+1},j}\\
\hline
x^\ell_{\setsize /2^{\ell+1}+1,j}\\\vdots\\x^\ell_{\setsize /2^\ell,j}
\end{pmatrix},
&\vecb{b}_\ell := 
\begin{pmatrix}
b_{1,\ell}\\\vdots\\b_{n,\ell}
\end{pmatrix},\\
&\vecb{x}_{1,j}^0 := \begin{pmatrix}
s_1\\\vdots\\s_{\setsize /2}
\end{pmatrix},\text{ and }
&\vecb{x}_{2,j}^0 := \begin{pmatrix}
s_{\setsize /2+1}\\\vdots\\s_{\setsize }
\end{pmatrix},
\end{align*}
and define new equations for each $\ell\in[m],j\in[m]$
\begin{align}
&\vecb{x}^\ell_j=\vecb{x}^{\ell-1}_{1,j}({1}-{b}_{j,\ell})+\vecb{x}^{\ell-1}_{2,j}{b}_{j,\ell},\label{eq-alog-1}\\
&x_j= \vecb{x}_{j}^m\label{eq-alog-1}
\end{align}

Next, we construct a QA-NIZK proof system for the language
\(
\Lang_{ck,\mathsf{set}}^n
\)
and in Section~\ref{sec:improved-aZKSMP-group-case} we show how to extend these ideas to show membership in the language
\(
\Lang_{ck,S}^n\)
for any \(S\subset\GG_1\), as defined at the beginning of this chapter.
The construction follows the intuition outlined before but it ``aggregates'' many instances on a single \(\Theta(\log \setsize )\) proof. From a high level this is done as follows:
\begin{itemize}
\item Given that now there are \(n\) bit-strings of size \(m\), the binary representation of $\alpha_1,\ldots,\alpha_n$, they are ``shrinked'' into \(m\) Multi-Pedersen commitments whose commitment keys are \([\vecb{h}_1]_2,\ldots,[\vecb{h}_{n+1}]_2\). Thereby, the variables $b_{i,1},\ldots,b_{i,m}$, which form the binary representation of $\alpha_i$, will be contained in \(m\) coefficients of \([\vecb{h}_i]_2\) of the $m$ Multi-Pedersen commitments to $\vecb{b}_1,\ldots,\vecb{b}_m$.
\item Commitments \([\vecb{c}_\ell]_1\) (we switched from index \(i\) to \(\ell\)) from the intuition, which contain the \(\setsize /2^\ell\) elements from \(S\) whose index prefix is \((b_1\cdots b_{\ell})\), should now contain \(n\setsize /2^\ell\) elements. Consequently, the commitment key \(ck_\ell\) is enlarged so that is able to contain the extra elements, and the coefficients of the elements from \(i\) th proof, \( i\in [n]\), are the ones from \([\vecb{g}_{i,1}^\ell]_1,\ldots,[\vecb{g}_{i,\setsize /2^\ell}^\ell]_1\).
\item Equation (\ref{eq-log-split}) is proven in the same way, enlarging the matrix as consequence of the enlargement of commitment keys.
\item Equations (\ref{eq-log-4}) and (\ref{eq-log-5}) are no longer proven using GS proofs, but using similar techniques as the ones from Chapter \ref{sec:bits}. We will have commitments whose discrete logs can be written as linear combinations of \(\vecb{g}_{i,1}^\ell,\ldots,\vecb{g}_{n,\setsize /2^\ell}^\ell\) and \(\vecb{h}_1,\ldots,\vecb{h}_{n+1}\). If we re-write equations (\ref{eq-log-4}) and (\ref{eq-log-5}) replacing \(b's\) with commitments and multiplication with the \emph{kronecker product} (that is, \(\vecb{x}\vecb{y}^\top\)), we will obtain an expression which at certain coefficients of \(\vecb{g}_{i,k}^\ell\vecb{h}_j^\top\) contains what we want and at others contains ``junk''. Similarly as done in Chapter \ref{sec:bits}, we will add two matrices \(\matr{\Theta}_\ell\) and \(\matr{\Pi}_\ell\) which will ``contain'' this junk and will help to balance the equation. It is only left to show that this new matrices are in the appropriate subspace and thus, they do not alter the equations we want to show to hold.
\item Soundness is proven in the same fashion as in the protocols from Chapter \ref{sec:shuf-rp}. That is, we guess one index \(j^*\in[n]\) such that \(x_{j^*}\notin S\) and choose the commitment keys in such a way that, at coordinate \(j^*\), the same equations of the non-aggregated case holds. This will imply that we lose an additional factor of \(1/n\) in the reduction and thus, the total security lost is a factor \(\frac{2}{n\setsize }\).
\end{itemize}
\subsubsection{The Scheme}

\begin{description}

\item[{\(\algK_1(\gk, ck)\)}:]
For each \(\ell\in [m]\) let \(\matr{G}^\ell:=\matr{G}^\ell_1||\cdots||\matr{G}^\ell_n||\vecb{g}^\ell_{n\setsize /2^\ell+1}\gets\distlin_1^{n\setsize /2^\ell,0}\), where
\[\matr{G}^\ell_i=
(\matr{G}^\ell_{i,1}|\matr{G}^\ell_{i,2})
=
(\vecb{g}^\ell_{i,1}\cdots\vecb{g}^\ell_{i,\setsize /2^{\ell+1}}|\vecb{g}^\ell_{i,\setsize /2^{\ell+1}+1}\cdots\vecb{g}^\ell_{i,\setsize /2^\ell})
\in\Z_q^{2\times\setsize /2^\ell},\] \(i\in  [n]\), and define \(ck_\ell:=[\matr{G}^\ell]_1\).
Let \(\matr{H}=\begin{pmatrix}\vecb{h}_1&\cdots&\vecb{h}_n&\vecb{h}_{n+1}\end{pmatrix}\gets\distlin_1^{n,0}\) and define \(ck':=[\matr{H}]_2\). 

Pick \(\matr{T}\gets\Z_q^{2\times 2}\) and for each \(\ell\in[m]\), \( i_1\in [n]\), \(i_2 \in [\setsize /2^\ell]\), \(j\in  [n+1]\), such that \(i_1\neq j\) or, \(i:=(i_1-1)\setsize /2^\ell+i_2=n\setsize /2^\ell+1\) and \(j=n+1\) define matrices
\[\matr{M}^\ell_{i,j}:=([\matr{C}_{i,j}^\ell]_1,[\matr{D}_{i,j}^\ell]_2):=([\vecb{g}_{i_1,i_2}^\ell\vecb{h}_j^{\top}+\matr{T}]_1,[-\matr{T}]_2),\]
For \(\ell\in [m]\) let \(\mathcal{M}_\ell\subset\GG_1^{2\times 2}\times\GG_2^{2\times 2}\) the set of the matrices \(\matr{M}\) whose super-index is \(\ell\) and define \(\mathcal{C}_\ell\subset\Z_q^{2\times 2}\) the set of matrices \(\matr{C}\) whose super-index is \(\ell\).

Let \(\Pi_\sfsum\) be the proof system for Sum in Subspace 
(Section~\ref{sec:sum}), \(\Pi_\mathsf{lin}\) the proof system for membership in linear subspaces from Section~\ref{sect:QANIZKlinspace}, \(\Pi_\sfbits\) the proof system for proving that many commitments open to bit-strings from section \ref{sec:matr-bits}, and \(\Pi_\sfcom\)
be an instance of the proof system for equal commitment opening (Section~\ref{sec:aggcommit}).

For each $\ell\in[m]$, let
\(\crs_{\sfsum,\ell} \gets \Pi_\sfsum.\algK_1(\gk, \mathcal{M}_\ell)\).\footnote{We identify
matrices in \(\GG_1^{2 \times 2}\) (respectively in \(\GG_2^{2 \times 2}\)) with vectors in \(\GG_1^{4}\) (resp. in \(\GG_2^{4}\)).}, let \(\crs_{\mathsf{lin},\ell}\gets \Pi_\mathsf{lin}.\algK_1(gk;\allowbreak[\matr{G}^\ell_{\mathsf{split}}]_1,n\setsize /2^{\ell}+3)\), let \(\crs_\sfbits\gets\Pi_\sfbits.\algK_1(gk,[\matr{H}]_2,m)\), and let \(\crs_\sfcom \gets \Pi_\sfcom.\algK_1(\gk, \bmatr{G}_1,\bmatr{H}_2,m)\), where
\[
\matr{G}_\mathsf{split}^\ell:=
\begin{pmatrix}
\matr{G}^{\ell}_{1,1} & \matr{G}^{\ell}_{1,2} & \cdots & \matr{G}^{\ell}_{n,1} & \matr{G}^{\ell}_{n,2} & \vecb{g}^{\ell}_{n\setsize /2^{\ell}+1} & \matr{0}                       & \matr{0}\\
\matr{G}^{\ell+1}_{1} & \matr{0}           & \cdots & \matr{G}^{\ell+1}_{n} & \matr{0}           & \matr{0}                    &\vecb{g}^{\ell+1}_{n\setsize /2^{\ell+1}+1} & \matr{0}\\
\matr{0}           & \matr{G}^{\ell+1}_{1} & \cdots & \matr{0}           & \matr{G}^{\ell+1}_{n} & \matr{0}                    & \matr{0}                       & \vecb{g}^{\ell+1}_{n\setsize /2^{\ell+1}+1}
\end{pmatrix}.
\]
The common reference string is given by:
\begin{eqnarray*}
\mathsf{crs}&:=&\left( gk, [\matr{G}]_1,
    [\matr{H}]_2, \{\mathcal{M}_\ell,\crs_{\sfsum,\ell},\crs_{\mathsf{lin},\ell}:\ell\in [m]\},\crs_\sfbits,\crs_\sfcom \right).
 \end{eqnarray*}


\item[{\(\algP(\mathsf{crs}, ([\grkb{\zeta}_1]_1, \ldots, [\grkb{\zeta}_n]_1,S), \langle (x_1,\ldots,x_n),(w_1,\ldots,w_n) \rangle)\)}:]
The prover compute commitments
\begin{align*}
&[\vecb{c}_\ell]_1:=\MP.\Com_{ck_\ell}({\vecb{x}^\ell_1}^\top,\ldots,{\vecb{x}^\ell_n}^\top;r_\ell), \text{ for } \ell \in [m],\\
&[\vecb{c}_{\ell,1}]_1:=\MP.\Com_{ck_\ell}({\vecb{x}^{\ell-1}_{1,1}}^\top,\ldots,{\vecb{x}^{\ell-1}_{1,n}}^\top;r_{1,\ell}),\\
&[\vecb{c}_{\ell,2}]_1:=\MP.\Com_{ck_\ell}({\vecb{x}^{\ell-1}_{2,1}}^\top,\ldots,{\vecb{x}^{\ell-1}_{2,n}}^\top;r_{2,\ell}), \text{ for } 1<\ell\leq m\\
&[\vecb{d}_\ell]_2:=\MP.\Com_{ck'}(\vecb{b}_\ell;t_\ell),\text{ for } i\in[m]
\end{align*}
 where \(r_\ell,r_{\ell,1},r_{\ell,2},t_j\gets\Z_q\) and the variables \(x^\ell_{j,\ell}\) are the ones defined in equation (\ref{eq-alog-1}). The prover computes a proof \(\pi_\sfbits\) that \([\vecb{d}_1]_2,\ldots,[\vecb{d}_m]_2\) open to bit-strings. Then, for \(\ell\in [m]\), the prover pick matrices \(\matr{R}_\ell\gets\Z_q^{2\times 2}\), computes
\begin{align*}
([\matr{\Theta}_\ell]_1,[\matr{\Pi}_\ell]_2)  := & \sum_{i=1}^n\sum_{j\neq i}\sum_{k=1}^{\setsize /2^\ell}(x^\ell_{k,i}-x^{\ell-1}_{k,i}(1-b_{j,\ell})-x^{\ell-1}_{\setsize /2^\ell+k,j}b_{j,\ell})\matr{M}_{(i-1)\setsize /2^\ell+k,j}^\ell\\
&+ \sum_{i=1}^n\sum_{k=1}^{\setsize /2^\ell}t_\ell(x^{\ell-1}_{k,i}-x^{\ell-1}_{\setsize /2^{\ell}+k,i})\matr{M}_{(i-1)\setsize /2^\ell+k,n+1}^\ell \\
&+ \sum_{j=1}^n (r_\ell-r_{1,\ell}(1-b_{j,\ell})-r_{2,\ell}b_{j,\ell})\matr{M}_{n\setsize /2^\ell+1,j}^\ell \\
&+(r_{1,\ell}-r_{2,\ell})t_\ell\matr{M}^\ell_{n\setsize /2^\ell+1,n+1}+([\matr{R}_\ell]_1,[-\matr{R}_\ell]_2),
\end{align*}
where \(r_{1,1}=r_{2,1}=0\), and computes proofs that
\begin{align*}
&\begin{pmatrix}
\vecb{c}_{\ell}\\\vecb{c}_{\ell+1,1}\\\vecb{c}_{\ell+1,2}
\end{pmatrix}\in
\Span(\matr{G}^{\ell}_\mathsf{split})\ (\text{ if }\ell< m), &\matr{\Theta_\ell}+\matr{\Pi_\ell}\in\Span(\mathcal{C}_\ell).
\end{align*}
Finally, it computes a proof \(\pi_\sfcom\) that \(([\grkb{\zeta}_1]_1,\ldots,[\grkb{\zeta}_n]_1)\) and \([\vecb{c}_m]_1\) open to the same value.

The proof is \(\pi:=(\{([\vecb{c}_\ell]_1,[\vecb{c}_{\ell,1}]_1,[\vecb{c}_{\ell,2}]_1,[\vecb{d}_\ell]_2,[\matr{\Theta}_\ell]_1,[\matr{\Pi}_\ell]_2,\pi_{\mathsf{lin},\ell},\pi_{\sfsum,\ell}):\ell\in [m]\},\pi_\sfbits,\pi_\sfcom)\).

\item[{\(\algV(\crs,([\grkb{\zeta}_1]_1, \ldots, [\grkb{\zeta}_n]_1,S),\pi)\)}:]
Let \([\vecb{c}_{1,1}]_1:=\MP.\Com_{ck_1}(s_1,\ldots,s_{\setsize /2};0),[\vecb{c}_{1,2}]:=\MP.\Com_{ck_1}(s_{\setsize /2+1},\ldots,s_{\setsize };0)\). The verifier checks the validity of \(\pi_\sfbits,\pi_\sfcom\) 
and, for each \(\ell\in [m]\), checks the validity of \(\pi_{\mathsf{lin},\ell},\pi_{\sfsum,\ell}\) and of equations
\begin{align}
&[\vecb{c}_\ell]_1\left(\sum_{j=1}^n [\vecb{h}_j]_2\right)^\top-
[\vecb{c}_{\ell,1}]_1\left(\sum_{j=1}^n[\vecb{h}_j]_2-[\vecb{d}_\ell]_2\right)^\top-
[\vecb{c}_{\ell,2}]_1[\vecb{d}_\ell]_2^\top = \nonumber\\
&[\matr{\Theta}_\ell]_1[\matr{I}]_2+[\matr{I}]_1[\matr{\Pi}_\ell]_2.  \label{eq-alog-5}
\end{align}

\item[{\(\mathsf{S}_1({gk},ck)\):}] The simulator receives as input a description of an asymmetric bilinear group \({gk}\) and a GS commitment key $ck$. It generates and outputs the CRS in the same way as \(\algK_1\), but additionally it also  outputs the simulation trapdoor 
\(\tau:=(\matr{H},\tau_\sfcom,\tau_\sfbits,\{\tau_{\sfsum,\ell},\tau_{\mathsf{lin},\ell}:\ell\in [m]\})\),
where \(\tau_{\sfsum},\tau_{\Psi_\sfbits},\tau_{\sfsum,\ell},\tau_{\mathsf{lin,\ell}}\) are, respectively, \({\Pi_\sfsum},{\Pi_\sfcom},\Pi_\sfsum,\Pi_\mathsf{lin}\) simulation trapdoors.

\item[{\(\mathsf{S}_2(\crs,([\grkb{\zeta}_1]_1,\ldots,[\grkb{\zeta}_n]_1,S),\tau)\):}] Define \(\vecb{x}^\ell_j:=\vecb{0}\) and \(\vecb{b}_\ell:=\vecb{0}\) for all \(\ell\in [m],j\in[n]\), and compute \([\vecb{c}_\ell]_1, [\vecb{c}_{\ell,1}]_1,[\vecb{c}_{\ell,2}]_1,[\vecb{d}_\ell]_2\) and \([\matr{\Theta}_\ell]_1,[\matr{\Pi}_\ell]_1\), as an honest prover would do (that is, with all variables set to 0).
Finally, simulate proofs \(\pi_\sfcom,\pi_\sfbits,\pi_{\sfsum,\ell},\pi_{\mathsf{lin},\ell}\) using the respective trapdoors.
\end{description}

We prove the following Theorem.

\begin{theorem} \label{theo:bits}
The proof system described above is a QA-NIZK proof system for the language \(\Lang_{ck,\mathsf{set}}^n\)
 with Perfect Completeness, Computational Soundness, and Perfect Zero-Knowledge.
\end{theorem}	

\subsubsection{Completeness}
Completeness follows from completeness of \(\Pi_\sfsum,\Pi_\mathsf{lin},\Pi_\sfbits,\Pi_\sfcom\), and from the fact that equation (\ref{eq-alog-5}) is satisfied for each \(\ell\in [m]\):
\begin{align*}
&\vecb{c}_\ell\left(\sum_{j=1}^n \vecb{h}_j\right)^\top-
\vecb{c}_{\ell,1}\left(\sum_{j=1}^n\vecb{h}_j-\vecb{d}_\ell\right)^\top-
\vecb{c}_{\ell,2}\vecb{d}_\ell^\top &= \\
&\sum_{i=1}^n\sum_{j=1}^n\matr{G}^\ell_i\vecb{x}^\ell_i\vecb{h}_j^\top+\sum_{j=1}^nr_\ell\vecb{g}_{n\setsize /2^\ell+1}^\ell\vecb{h}_j^\top
-\sum_{i=1}^n\sum_{j=1}^n\matr{G}^\ell_i\vecb{x}^{\ell-1}_{1,i}(1-b_{j,\ell})\vecb{h}_j^\top\\
&+\sum_{i=1}^n\matr{G}^\ell_i\vecb{x}^{\ell-1}_{1,i} t_\ell\vecb{h}_{n+1}^\top-\sum_{j=1}^nr_{1,\ell}\vecb{g}^\ell_{n\setsize /2^\ell+1}\vecb{h}_j^\top+ r_{1,\ell}t_\ell\vecb{g}^\ell_{n\setsize /2^\ell+1}\vecb{h}_{n+1}^\top\\
&-\sum_{i=1}^n\sum_{j=1}^n\matr{G}^\ell_i\vecb{x}^{\ell-1}_{2,i}b_{j,\ell}\vecb{h}_j^\top-\sum_{i=1}^n\matr{G}^\ell_i\vecb{x}^{\ell-1}_{2,i} t_\ell\vecb{h}_{n+1}^\top-\sum_{j=1}^nr_{2,\ell}\vecb{g}^\ell_{n\setsize /2^\ell+1}\vecb{h}_j^\top\\
&- r_{2,\ell}t_\ell\vecb{g}^\ell_{n\setsize /2^\ell+1}\vecb{h}_{n+1}^\top &=\\
&\sum_{i=1}^n\sum_{j\neq i}\matr{G}^\ell_i(\vecb{x}^\ell_i-(\vecb{x}^{\ell-1}_{1,i}(1-b_{j,\ell})+\vecb{x}^{\ell-1}_{2,1}b_{j,\ell}))\vecb{h}_j^\top+\\
&\sum_{i=1}^n\matr{G}^\ell_i(\vecb{x}^{\ell-1}_{1,i}-\vecb{x}^{\ell-1}_{2,i})t_\ell\vecb{h}_{n+1}^\top+\sum_{j=1}^n(r_\ell-r_{1,\ell}-r_{2,\ell})\vecb{g}_{n\setsize /2^\ell+1}^\ell\vecb{h}_{j}^\top\\
&+(r_{1,\ell}-r_{2,\ell})t_\ell\vecb{g}^\ell_{n\setsize /2^\ell+1}\vecb{h}_{n+1}^\top &=\\
&\sum_{i=1}^n\sum_{j\neq i}\sum_{k=1}^{\setsize /2^\ell}(x_{k,i}^\ell-(x_{k,i}^{\ell-1}(1-b_{j,\ell})+x_{\setsize /2^\ell+k,i}^{\ell-1}b_{j,\ell})))\vecb{g}_{(i-1)\setsize /2^\ell+k}^\ell\vecb{h}_j^\top\\
&+\sum_{i=1}^n\sum_{k=1}^{\setsize /2^\ell}t_\ell(x_{k,i}^{\ell-1}-x_{\setsize /2^\ell+k,i}^{\ell-1})\vecb{g}_{(i-1)\setsize /2^\ell+k}^\ell\vecb{h}_{n+1}^\top\\
&\sum_{j=1}^n(r_\ell-r_{1,\ell}-r_{2,\ell})\vecb{g}_{n\setsize /2^\ell+1}^\ell\vecb{h}_{j}^\top+(r_{1,\ell}-r_{2,\ell})t_\ell\vecb{g}^\ell_{n\setsize /2^\ell+1}\vecb{h}_{n+1}^\top &=\\
&\matr{\Theta}\matr{I}+\matr{I}\matr{\Pi}.
\end{align*}

\subsubsection{Soundness}

The following theorem guarantees Soundness. 
 
\begin{theorem} Let \(\mathsf{Adv}_{{\Pi_\sfset}}(\advA)\) 
be the advantage of an adversary \(\advA\) against the soundness of 
the proof system  described above. There exist PPT adversaries
\(\advD_1,\advD_2,\advB_\sfbits,\advB_\sfcom,\advB_\sfsum,\advB_\mathsf{lin}\) such that 
\begin{align*}
\mathsf{Adv}_{{\Pi_\sfset}}(\advA) \leq 
n \left(\right.
    &\mathsf{Adv}_{\mathcal{L}_1,\Gr}(\advD_1) 
        + \setsize /2\left(4/q
            +  \mathsf{Adv}_{\Pi_\sfbits}(\advB_\sfbits)
            +  \mathsf{Adv}_{\mathcal{L}_1,\Hr}(\advB_2)\right. \\
    &+ \left.\left.\mathsf{Adv}_{{\Pi_\sfcom}}(\advB_\sfcom)
        + m\mathsf{Adv}_{{\Pi_\sfsum}}(\advB_\sfsum)
        + m\mathsf{Adv}_{{\Pi_\mathsf{lin}}}(\advB_\mathsf{lin})\right)\right).
\end{align*}
\label{teo:bitstr-soundness}
\end{theorem}

The proof follows from the indistinguishability of the following games:
\begin{itemize}
\item[\(\mathsf{Real}\):] This is the real Soundness game. The output is 1 if the adversary submits some \(([\grkb{\zeta}_1]_1,\ldots,[\grkb{\zeta}_n]_1,S)\notin\Lang_{ck,\mathsf{set}}^n\) and the corresponding proof which is accepted by the verifier.
\item[\(\sfGame_0\):] This identical to \(\mathsf{Real}\), except that \(\algK_1\) does not receive \(ck\) as a input but
it samples \(ck\) itself together with its discrete logarithms.
\item[\(\sfGame_1\):] This game is identical to \(\sfGame_0\) except that now it chooses random \(j^*\in[n]\) and it aborts if \(x_{j^*}\notin S\).
\item[\(\sfGame_2\):] This game is identical to \(\sfGame_1\) except that now \(\matr{H}\gets\distlin^{n,j^*}_1\).
\item[\(\sfGame_3\):] This game is identical to \(\sfGame_2\) except that now it chooses \((b_2\cdots b_m)\gets \setsize /2\) (recall that \((b_1\cdots b_m)=\sum_{i=1}b_i2^{m-i}+1\)) and aborts if \((b_{j^*,1},\ldots,b_{j^*,m})\notin\bits^m\) or \((b_2\cdots b_m)\neq(b_{j^*,2}\cdots b_{j^*,m})\), where \(b_{j^*,2},\ldots,b_{j^*,m}\) are the openings of \([\vecb{d}_2]_2,\ldots,[\vecb{d}_m]_2\) at coordinate \(j^*\), respectively.
\item[\(\sfGame_4\):] This game is identical to \(\sfGame_3\) except that now \(\matr{G}^\ell\gets\distlin_1^{n\setsize /2^\ell,(j^*-1)\setsize /2^\ell+(b_{\ell+1}\cdots b_m)}\), for \(\ell\in [m]\).
\end{itemize}

It is obvious that the first two games are indistinguishable. The rest of the argument goes as follows.

\begin{lemma}
\(\Pr\left[ \mathsf{Game}_1(\advA)=1\right]\geq\dfrac{1}{n}\Pr\left[\mathsf{Game}_0(\advA)=1\right].\)
\end{lemma}

\begin{proof}  The probability that
 \(\mathsf{Game}_1(\advA)=1\) is the probability that  a) \(\mathsf{Game}_0(\advA)=1\) and
b)  \(x_{j^*} \notin S\). The view of adversary \(\advA\) is independent of \(j^*\), while, if \(\mathsf{Game_0}(\advA)=1\), then there is at least one index \(j \in [n]\) such that  
such that  \(x_{j} \notin S\). Thus, 
the probability that the event described in b) occurs conditioned on \(\mathsf{Game_0}(\advA)=1\), is greater than or equal to \(1/n\) and the lemma follows.
\end{proof}

\begin{lemma} There exists a\ \(\distlin_1\)-\(\mddh_{\GG_2}\) adversary \(\advD_2\) such that
\(|\Pr\left[\mathsf{Game}_{1}(\advA)=1\right]\linebreak-\Pr\left[\mathsf{Game}_{2}(\advA)=1\right]|\) \(\leq \mathsf{Adv}_{\distlin_1,\ggen_a}(\advD_2).\)
\end{lemma}
\begin{proof}
We construct an adversary \(\advD_2\) that receives 
a challenge \(([\vecb{a}]_2,[\vecb{u}]_2)\) of the 
\(\distlin_1\)-\(\mddh_{\GG_2}\) Assumption. From this challenge, \(\advD_2\) just defines the matrix  \([\matr{H}]_2\in\GG_2^{2\times(n+1)}\) as the matrix whose last column is \([\vecb{a}]_2\), the ith column is \([\vecb{u}]_2\), and the rest of the columns are random vectors in the image of \([\vecb{a}]_2\). 
Obviously, when \([\vecb{u}]_2\) is sampled from 
the image of \([\vecb{a}]_2,\) \(\matr{H}\) follows the distribution \(\distlinizeroone\), while if \([\vecb{u}]_2\) is a uniform element of \(\GG^2_2\), \(\matr{H}\) follows the distribution \(\distlin_1^{n,j^*}\). 
 
Adversary \(\advD_2\) samples
\(\matr{G}^\ell \gets \distlin_1^{n\setsize /2^\ell,0}\). Given that \(\advD_2\) does not know the discrete logarithms of \([\matr{H}]_2\), it cannot compute the pairs \((\matr{C}^\ell_{i,j},\matr{D}^\ell_{i,j})\) exactly as in \(\sfGame_0\). Nevertheless, for each \(i,j,\ell\) it can compute identically distributed pairs by picking \(\matr{T}\gets\Z_q^{2\times 2}\) and defining
\[
([\matr{C}^\ell_{i,j}]_1,[\matr{D}^\ell_{i,j}]_2):=([\matr{T}]_1,\vecb{g}_{i_1,i_2}^\ell[\vecb{h}_j]_2^\top-[\matr{T}]_2),
\]
where \(i=(i_1-1)\setsize /2^\ell+i_2\) for some \(1\leq i_1\leq n,1\leq i_2 \leq \setsize /2^\ell\).

The rest of the elements of the CRS are honestly computed. When \(\matr{H}\gets\distlin_1^{n,0}\), \(\advD_2\) perfectly simulates \(\sfGame_0\), and when \(\matr{H}\gets\distlin_1^{n,j^*}\), \(\advD_2\) perfectly simulates \(\sfGame_1\), which concludes the proof. 
\end{proof}

\begin{lemma} There exists an adversary \(\advB_\sfbits\) against \(\Pi_\sfbits\) such that
\(\Pr\left[ \mathsf{Game}_2(\advA)=1\right]\geq\dfrac{2}{\setsize }(\Pr\left[\mathsf{Game}_3(\advA)=1\right]+\adv_{\Pi_\sfbits}(\advB_\sfbits)).\)
\end{lemma}

\begin{proof}  The probability that
 \(\mathsf{Game}_3(\advA)=1\) is the probability that  a) \(\mathsf{Game}_2(\advA)=1\) and
b) \((b_{j^*,1},\ldots,b_{j^*,m})\notin\bits^m\) or \((b_2\cdots b_m) \neq (b_{j^*,2}\cdots b_{j^*,m})\). If \((b_{j^*,1},\ldots,\allowbreak b_{j^*,m})\notin\bits^m\) we can build an adversary \(\advB_\sfbits\) against \(\Pi_\sfbits\) and thus, the probability that \((b_{j^*,1},\ldots,b_{j^*,m})\in\bits^m\) is less than \(\adv_{\Pi_\sfbits}(\advB_1)\). The view of adversary \(\advA\) is independent of \((b_{2}\cdots b_{m})\), while, if \(\mathsf{Game_2}(\advA)=1\) and \((b_{j^*,1},\ldots,b_{j^*,m})\in\bits^{m}\), then \((b_{j^*,2}\cdots b_{j^*,m})\in[\setsize /2]\). Thus, 
the probability that the event described in b) occurs conditioned on \(\mathsf{Game_0}(\advA)=1\) and \((b_{j^*,1},\ldots,b_{j^*,m})\in\bits^{m}\), is greater than or equal to \(2/\setsize \) and the lemma follows.
\end{proof}

\begin{lemma} There exists a \(\distlin_1\)-\(\mddh_{\GG_1}\) adversary \(\advD_1\) such that
\(|\Pr\left[\mathsf{Game}_{3}(\advA)=1\right]\allowbreak-\Pr\left[\mathsf{Game}_{4}(\advA)=1\right]|\) $\leq
    \mathsf{Adv}_{\distlin_1,\GG_1}(\advD_1).$
\label{lemma:bits2}
\end{lemma}

\begin{proof}
We construct an adversary \(\advD_1\) that receives 
a challenge \(([\vecb{a}]_1,[\vecb{u}]_1)\) of the 
\(\distlin_1\)-\(\mddh_{\GG_1}\) Assumption. From this challenge, \(\advD_1\) defines for each \(\ell\in [m]\) the matrix  \([\matr{G}^\ell]_1\) as the matrix whose  \((j^*-1)\setsize /2^\ell+(b_{\ell+1}\cdots b_m)\) th column is \([\vecb{u}]_1\), and the rest of the columns are random vectors in the image of \([\vecb{a}]_1\). 
Obviously, when \([\vecb{u}]_1\) is sampled from 
the image of \([\vecb{a}]_1\), \([\matr{G}^\ell]_1\) follows the distribution \(\distlin_1^{n\setsize /2^\ell,0}\), while if \([\vecb{u}]_1\) is a uniform element of \(\GG^2_1\), \([\matr{G}^\ell]_1\) follows the distribution \(\distlin_1^{n\setsize /2^\ell,(j^*-1)\setsize /2^\ell+(b_{\ell+1}\cdots b_m)}\). 
 
The rest of the elements of the CRS are honestly computed. When \([\vecb{u}]_1\) is sampled from the image of \([\matr{a}]_1\), \(\advD_1\) perfectly simulates \(\sfGame_3\), and when \([\vecb{u}]_1\) is uniform, \(\advD_1\) perfectly simulates \(\sfGame_4\), which concludes the proof. 
\end{proof}


\begin{lemma}
There exist adversaries \(\advB_\sfcom\), against the strong soundness of \(\Pi_\sfcom\), \(\advB_\sfsum\), against the soundness of \(\Pi_\sfsum\), and an adversary \(\advB_\mathsf{lin}\) against the soundness of \(\Pi_\mathsf{lin}\), such that \(\Pr[\sfGame_4(\advA)=1]\leq 4/q+ \adv_{\Pi_\sfcom}(\advB_\sfcom)+m\adv_{\Pi_\sfsum}(\advB_\sfsum)+m\adv_{\Pi_\mathsf{lin}}(\advB_\mathsf{lin})\).
\end{lemma}
\begin{proof}
With probability \(1-4/q\), \(\{\vecb{g}_{j^*,(b_{\ell+1\cdots b_m})}^\ell,\vecb{g}_{n\setsize /2^\ell+1}^\ell\}\), \(\ell\in [m]\), and \(\{\vecb{h}_{i^*},\allowbreak \vecb{h}_{m+1}\}\) are bases of \(\Z_q^2\),
and, for each \(\ell\in [m],\mu\in\{1,2\}\), we can define \(\tilde{s}^\ell,\tilde{s}^{\ell-1}_\mu,\tilde{r}_\ell,\tilde{r}_{\mu,\ell},b_{j^*,\ell},\tilde{t}_\ell\) as the unique coefficients in \(\Z_q\) such that \(\vecb{c}_\ell=\allowbreak \tilde{s}^\ell\vecb{g}_{j^*,(b_{\ell+1}\cdots b_m)}^\ell + \tilde{r}_\ell \vecb{g}_{n\setsize /2^\ell+1}^\ell, \vecb{c}_{\ell,\mu}=\tilde{s}^{\ell-1}_\mu\vecb{g}_{j^*,(b_{\ell+1}\cdots b_m)}^\ell + \tilde{r}_{\mu,\ell} \vecb{g}_{n\setsize /2^\ell+1}^\ell,\) and \(\vecb{d}_\ell= b_{j^*,\ell} \vecb{h}_{j^*} + \tilde{t}_\ell \vecb{h}_{n+1}\).

Recall that if \(\sfGame_4(\advA)=1\) then \(x_{j^*}\notin S\). The adversary can win in \(\sfGame_4\) if one of the following events happen:
\begin{description}
\item[\(E_1\):] the adversary breaks soundness of \(\Pi_\sfcom\) and \(x_{j^*}\neq \tilde{s}^m\),
\item[\(E_2\):] the adversary breaks one of the \(m\)  instances of \(\Pi_\sfsum\) and \(\matr{\Theta}_\ell+\matr{\Pi}_\ell\notin\Span(\mathcal{C}_\ell)\),
\item[\(E_3\):] the adversary breaks one of the \(m\) instances of \(\Pi_\sflin\) and \((\vecb{c}_{\ell},\vecb{c}_{\ell+1,1},\vecb{c}_{\ell+1,2})\notin\Span(\matr{G}_\mathsf{split}^\ell)\),
\item[\(E_4\):] neither of \(E_1\),\(E_2\), or \(E_3\) happens, but \(x_{j^*}\notin S\) anyway.
\end{description}
By the law of total probabilities, \(\Pr[\sfGame_4(\advA)=1]\leq 4/q+\Pr[E_1]+\Pr[E_2]+\Pr[E_3]+\Pr[E_4]\), and is not hard to see that there exist adversaries \(\advB_\sfcom,\advB_\sfsum,\advB_\mathsf{lin}\) such that \(\Pr[E_1]=\adv_{\Pi_\sfcom}(\advB_\sfcom),\Pr[E_2]=m\adv_{\Pi_\sfsum}(\advB_\sfsum),\) and \(\Pr[E_3]=m\adv_{\Pi_\mathsf{lin}}(\advB_\mathsf{lin})\). Below we will show that \(\Pr[E_4]=0\) (using the same argument used in the non-aggregated case).

We prove by induction on \(\ell\) that \(\tilde{s}^\ell=s_{(b_1\cdots b_m)}\), where \(b_1:=b_{j^*,1}\). If this is the case, the fact that \(\neg E_1\) implies that \(x_{j^*}=\tilde{s}^m=s_{(b_1\cdots b_m)}\in S\) and we are ready. In the base case, if we multiply equation (\ref{eq-alog-5}) on the right by a vector \(\vecb{k}\) such that \(\vecb{h}_j^\top\vecb{k}=1\) if \(j=j^*\) and \(0\) if not (which exists since \(\{\vecb{h}_{j^*},\vecb{h}_{n+1}\}\) is a basis of \(\Z_q^2\)), together with the fact that \(\matr{\Theta}_1+\matr{\Pi}_1\in\Span(\mathcal{C}_1)\), and the fact that \(\vecb{c}_{1,1}=s_{0b_{2}\cdots b_{m}} \vecb{g}_{j^*,(b_{2}\cdots b_{m})}^1\) and \(\vecb{c}_{1,2}=s_{1b_{2}\cdots b_{m}}\vecb{g}_{j^*,(b_{2}\cdots b_{m})}^1\) implies that 
\begin{align*}
\vecb{c}_1 &= (1-b_{1})s_{(0b_{2}\cdots b_{m})} \vecb{g}_{j^*,(b_{2}\cdots b_{m})}^1+b_{1}s_{(1b_{2}\cdots b_{m})}\vecb{g}_{j^*,(b_{2}\cdots b_{m})}+\tilde{r}_1\vecb{g}_{n\setsize /2+1}^1\\
&=s_{(b_{1}\cdots b_{m})}\vecb{g}_{1,(b_{2}\cdots b_{m})}+\tilde{r}_1\vecb{g}_{n\setsize /2+1}^1.
\end{align*}

In the inductive case we assume that \(\vecb{c}_{\ell-1}=s_{(b_1\cdots b_m)}\vecb{g}_{j^*,(b_\ell\cdots b_m)}^{\ell-1}+\tilde{r}_{\ell-1}\vecb{g}_{n\setsize /2^{\ell-1}+1}^{\ell-1}\). Since \(\vecb{g}_{j^*,(b_\ell\cdots b_m)}^{\ell-1}\) is linearly independent from the rest of vectors in \(ck_{\ell-1}\), any solution to equation
\[
\begin{pmatrix}\vecb{c}_{\ell-1}\\\vecb{c}_{\ell,1}\\\vecb{c}_{\ell,2}\end{pmatrix}=\matr{G}^{\ell-1}_{\mathsf{split}}\vecb{w}
\]
 is equal to \(s_{(b_1\cdots b_m)}\) at position \((b_\ell \cdots b_m)\). An analysis of the two cases \(b_\ell=0\) or \(b_\ell=1\) shows that \(\vecb{c}_{\ell,b_\ell+1}=s_{(b_1\cdots b_m)}\vecb{g}_{j^*,(b_{\ell+1}\cdots b_m)}^\ell+\tilde{r}_{\ell,b_i+1}\vecb{g}_{n\setsize /2^\ell+1}^\ell\). Finally, equation (\ref{eq-alog-5}) implies that \(\vecb{c}_\ell=s_{(b_1\cdots b_m)}\vecb{g}_{j^*,(b_{\ell+1}\cdots b_m)}^\ell+\tilde{r}_\ell\vecb{g}_{n\setsize /2^\ell+1}^\ell\).
\end{proof}

\subsubsection{Perfect Zero-Knowledge}
Note that the vector the vectors \([\vecb{c}_\ell],[\vecb{c}_{\ell,1}]_1,[\vecb{c}_{\ell,2}]_1,[\vecb{d}_\ell]_2\) and matrices \([\matr{\Theta}_\ell]_1,[\matr{\Pi}_\ell]_2\), \(1\leq\ell\leq m\), output by the prover and the simulator are, respectively, uniform vectors and uniform matrices conditioned on satisfying equation \ref{eq-alog-5}. This follows from the fact that \(ck',ck_1,\ldots,ck_\ell\) are all perfectly hiding commitment keys and that \([\matr{\Theta}_\ell]_1,[\matr{\Pi}_\ell]_1\) are the unique solutions of equation (\ref{eq-alog-5}) modulo the random choice of \(\matr{R}_\ell\). Finally, the rest of the proof follows from Zero-Knowledge of \(\Pi_\sfcom,\Pi_\sfbits,\Pi_\sfsum,\) and \(\Pi_\mathsf{lin}\).

\subsection{The case \(S\subset\GG_1\)} \label{sec:improved-aZKSMP-group-case}
We briefly justify that the case \(S\subset\GG_1\) follows directly from the case \(S\subset\Z_q\) when \(S\) is a fixed witness samplable set. That is, there is a fixed set $S$ for each CRS, and there is an efficient algorithm that samples \(s_1,\ldots,s_{\setsize }\in\Z_q\) such that \(S=\{[s_1]_1,\ldots,[s_{\setsize }]_1\}\). %Note that this is the same case of Section~\ref{sec:bits-applications} where the CRS depends on set.

The reason why is not clear how to compute proofs in this setting is that it requires to compute values of the type \([\vecb{s}_i\vecb{k}]_1\), where \([\vecb{k}]_\mu\), \(\mu\in\{1,2\}\), is a vector from one of the commitment keys. The solution is straightforward: use \(s_1,\ldots,s_{\setsize }\) to compute this values and add them to the CRS (with the consequent CRS growth). Therefore, the new CRS contains also:
\begin{align*}
&[s_i\vecb{g}_{j,k}^\ell]_1 \text{ for } i,j\in [n], \ell\in [m], k\in[\setsize /2^\ell]\\
& s_i([\matr{C}^\ell_{j,k}]_1,[\matr{D}_{j,k}^\ell]_2) \text{ for } i,k\in [n], \ell\in [m], j\in [n\setsize /2^\ell].
\end{align*}

\subsection{Application: Theoretical \(\Theta(\log n)\) Ring Signature} \label{sec:log-ring-signature}

In this section we will describe how the improved aZKSMP can be used to obtain a \emph{theoretical} Ring Signature with signature size \(\Theta(\log n)\), where \(n\) is the size of the ring, in the standard model (i.e. without \emph{Random Oracles} nor \emph{Non-Falsifiable Assumptions}). In other words we show that there exist Set-Membership proofs of size \(\Theta(\log \setsize )\) even when \(S\subset \GG_1\) is not fixed (that is, prove membership in $\Lang_{ck,\mathsf{set}}^n\subset\GG_s^n$),\footnote{It seems that in the aggregated case this is also true. However, we leave this as an open problem.} and from this proof is direct to construct a Ring Signature using the techniques of Chandran et al.~\cite{ICALP:ChaGroSah07}.

We say that our construction is theoretical because, although the asymptotic signature size is \(\Theta(\log n)\), we use general results of NP-completeness and thus the ``real'' signature size is \(\Theta(\log n)+\mathsf{poly}(\lambda)\), where \(\lambda\) is the security parameter. Nonetheless, our result should be interpreted as a feasibility result and it poses the interesting question of whether the \(\mathsf{poly}(\lambda)\) part can be reduced to a practical value.

Lets see in a little more detail what is hidden in the asymptotics. When working on bilinear groups, the size of the proof is usually measured in number of group elements, and thus, if the proof is of size $f(n)$ groups elements its size in bits is $|\GG_s|f(n)$. Since $|\GG_s|$ is a linear function of the security parameter (and in practice of the order of one kilobit for $\lambda=128$) it is always ignored. In our case our proof additionally adds a constant number of group elements, with respect to $n$, but for which we only know that is upper bounded by some polynomial of $\lambda$. Therefore, although this part of the proof is independent of $n$, it is misleading to ignore its contribution to the total proof size.
 
We define an encoding function \(\mathcal{E}:\GG_1\cup\GG_2\to\bits^\ell\), where \(\ell=\mathsf{poly}(\lambda)\), which translates group elements to their natural bit encoding. Given a ring \(R=\{[vk_1]_1,\ldots,[vk_n]_1\}\) and \([vk]\in R\), we commit to \(\vecb{x}:=\mathcal{E}([vk]_1)\) using GS commitments and show that \(\mathcal{E}([vk]_1)\in\mathcal{E}(R)\), bit-by-bit, using the improved aZKSMP for \(S\subset \Z_q\). Let \([\vecb{c}]_1:=\GS.\Com_{ck}(\vecb{x}^\top;\matr{R}^\top)=([\vecb{c}_1]||\cdots||[\vecb{c}_\ell])\in\GG_1^{2\times \ell}\) and compute \([\vecb{d}]_1:=\GS.\Com_{ck}([vk]_1;(w_1,w_2)^\top)\), we would like to show that \(\mathcal{E}([vk]_1)=\vecb{x}\).

Given \(\vecb{x}\in\bits^\ell\), there exists a circuit \(C(\vecb{x},\vecb{w}_1,\vecb{w}_2,\vecb{y})\) that interprets \(\vecb{x},\vecb{w}_1,\vecb{w}_2\) as  elements \([x]_1,w_1,w_2\) of \(\GG_1,\Z_q,\Z_q\), respectively, and \(\vecb{y}\) as an element \([\vecb{d}]_1\) of \(\GG_1^2\), computes the bit-string
\begin{align*}
\vecb{s}:=
    &C_{\GG_1,-}(\\
        &\quad C_{\GG_1,-}(\\
            &\qquad C_{\GG_1,-}\left(
                \vecb{y},
                \mathcal{E}\left(
                        ({[x]_1},{[0]_1})^\top\right)\right),\\
            &\qquad C_{\GG_1,\cdot}(
                        \vecb{w}_1,
                        \mathcal{E}([\vecb{u}_1]_1)),\\
        &\quad C_{\GG_1,\cdot}(
                    \vecb{w}_2,
                    \mathcal{E}([\vecb{u}_2]_1)),
\end{align*}
where the circuit $C_{\GG_1,-}:\bits^{2\ell}\to\bits^\ell$ computes the substraction (inverse and addition computation) of two elements of $\GG_1$, and the circuit $C_{\GG_1,\cdot}:\bits^{\log q+\ell}\to\bits^\ell$ computes the multiplication of an element from $\GG_1$ and an integer in $\Z_q$, and where \(([\vecb{u}_1]||[\vecb{u}_2]_1)=ck\). That is, $C$ is computing an encoding of $[\vecb{d}]_1-([x]_1,[0]_1)^\top-w_1[\vecb{u}]_1-w_2[\vecb{u}_2]$. Finally, $C$ returns 1 iff \(\vecb{s}=\mathcal{E}([0]_1)\). Using the NIZK proof system for Circuit Satisfiability of Groth et al.~\cite{EC:GroOstSah06} we can prove this statement with a proof of size \(\Theta(|C|)=\mathsf{poly}(\lambda)\), because \(|C|\) only depends on \(q=\poly(\lambda)\) and \(\ell=\poly(\lambda)\).

We conclude that we can prove that \([vk]_1\in R\) with a proof of size \(\Theta(\log n +\poly(\lambda))=\Theta(\log n)\), and thus we can construct a ring signature with signature size \(\Theta(\log n)\)
