\newcommand{\setsize}{t}

In this section we show that for any subset \(S\subset\Z_q\) such that \(|S|=\poly(\lambda)\) one can construct an aZKSMP whose size is \(\Theta(\log|S|)\). We then show how to translate these results to fixed subsets \(S\subset\mathbb{G}_s\), \(s\in\{1,2\}\), i.e~when the proof system's CRS is fixed to a specific set \(S\).

On Section~\ref{sec:aZKSMP} we built a proof system for the case \(S=[0,2^n-1]\) with the same proof size, however, when \(S\) was not of this form, the proof size was \(\Theta(|S|)\). When \(S\) is a fixed subset of \(\GG_s\), the proof system from Section~\ref{sec:aZKSMP} also requires proofs of size \(\Theta(|S|)\).

Our proof bears some similarities with the work of Groth and Kohlweiss \cite{EC:GroKoh15} -- both allow to construct proofs of membership in a set of logarithmic size using the binary encoding of the element index -- but they are in general incomparable. Indeed, Groth and Kohlweiss's construction is on a different setting (interactive, without pairings) and does not support aggregation of many proofs.

\subsection{Intuition}

For simplicity, we will restrict to the case \(S=\{s_1,\ldots,s_\setsize \}\subset\Z_q\) without aggregation, that is, there is a single commitment \([\vecb{c}]_1=\GS.\Com_{ck}(x;r)\) and we want to show that \(x=s_\alpha\), for some \(\alpha\in[\setsize ]\). Then we will show how to aggregate many proofs.

The (non-aggregated) proof from Section~\ref{sec:aZKSMP} essentially codifies the position \(\alpha\) as a weight 1 binary vector \(\vecb{b}\) of size \(\setsize \) such that \(x=\sum_{i\in[\setsize ]}b_is_i\) and
\(b_i=1\) if \(i=\alpha\) and \(0\) if not.\footnote{The case \(S\subset\Z_q\) is not really discussed in Section~\ref{sec:aZKSMP}, but it is straightforward that the same techniques from the case \(S\subset\GG_s\) apply.} A step further in efficiency was given by Chandran et al.~\cite{ICALP:ChaGroSah07} (already discussed in Section~\ref{sec:bits-applications}). There the position \(\alpha\) is codified as two weight 1 binary vectors \(\vecb{b}\) and \(\vecb{b}'\) of size \(\sqrt{\setsize }\) such that
\[
\begin{pmatrix}
x_1\\\vdots\\x_{\sqrt{\setsize }}
\end{pmatrix}
=\sum_{i=1}^{\sqrt{\setsize }}b_i
\begin{pmatrix}
s_{(i-1)\sqrt{\setsize }+1}\\\vdots\\s_{(i-1)\sqrt{\setsize }+\sqrt{\setsize }}
\end{pmatrix},
\text{ } x=\sum_{i=1}^{\sqrt{\setsize }}b'_ix_i,\]
and \(b_i=1\) iff \(i=i_\alpha\) and \(b'_j=1\) iff \(j=j_\alpha\), where \(\alpha=(i_\alpha-1)\sqrt{\setsize }+j_\alpha\). Since \(\sqrt{\setsize }\) new variables are added (variables \(x_1,\ldots,x_{\sqrt{\setsize }}\)), the proof must contain \(\sqrt{\setsize }\) new commitments to these variables. However, this does not not affect the asymptotic size of the proof, which is \(\Theta(\sqrt{\setsize })\) anyway.


Let $m:=\log \setsize$.\footnote{ W.l.o.g.~we assume that \(\log \setsize \in\mathbb{N}\), because we can always prove membership in the (multi-)set \(S'=S\biguplus_{i=1}^{2^{\lceil \log \setsize  \rceil}-\setsize}\{s_{\setsize} \}\) and it holds that $|S'|=2^{\lceil \log t \rceil}$ and that $x\in S \Longleftrightarrow x\in S'$.} The natural next step is to codify \(\alpha\) as \(m\) weight 1 binary vectors of size 2 (note that a weight 1 binary vector of size 2 can be always written as \((1-b,b)\), \(b\in\bits\) ) such that
\begin{align}
&\begin{pmatrix}
x_{\ell,1}\\\vdots\\x_{\ell,{2^{\ell-1}}}
\end{pmatrix}
=
(1-b_\ell)
\begin{pmatrix}
x_{\ell+1,1}\\\vdots\\x_{\ell+1,{2^{\ell-1}}}
\end{pmatrix}
+
b_\ell
\begin{pmatrix}
x_{\ell+1, 2^{\ell-1}+1}\\\vdots\\x_{\ell+1,2^{\ell}}
\end{pmatrix}
\text{ if } \ell \in[m],\label{eq-log-2}\\
&
x= x_{1,1}\label{eq-log-3},
\end{align}
where \(x_{m+1,i}:=s_i\), \(i\in[2^m]\), and \(\alpha=\sum_{i=1}^{m}b_i2^{i-1}+1\). Note that we have added the additional variables \(x_{\ell,i}\), \(\ell\in[m]\) and \(i\in[2^\ell]\).

Consider the binary tree whose leafs are $x_{m+1,1}=s_1,\ldots,x_{m+1,2^m}=s_{2^m}$, where the leftmost leaf is $s_1$ and the rightmost leaf is $s_{2^m}=s_t$. Intuitively, equation (\ref{eq-log-2}) for $\ell=m$ says that variables $x_{m,1},\ldots, x_{m,2^{m-1}}$ are the leafs of the subtree under the path $b_m$. For example, if $b_m=1$, the variables $x_{m,1},\ldots,x_{m,2^{m-1}}$ are equal to $s_{2^{m-1}+1},\ldots,s_{2^m}$, which are the leafs of the subtree under the path 1 as depicted below.
\begin{center}
\begin{tikzpicture}
[n/.style={draw=none},
 every node/.append style={inner ysep=+0pt,outer ysep=+0pt,minimum size=+0pt}]
%\hspace{-3.9cm}
\Tree 
    [.{}
        \edge node[auto=right] {\small 0};
        \qroof{\parbox{\widthof{$s_{2^{m-1}+1}\cdots s_{2^m}$}}{\vspace*{.1cm}$s_1$\hfill$\cdots$\hfill$s_{2^{m-1}}$}}.{}
        \edge node[auto=left] {\small 1};
        \qroof{\parbox{\widthof{$s_{2^{m-1}+1}\cdots s_{2^m}$}}{\vspace*{.1cm}$s_{2^{m-1}+1}\cdots s_{2^m}$}}.{}
    ]
\end{tikzpicture}
\end{center}
Similarly, equation (\ref{eq-log-2}) for $\ell=m-1$ says that variables $x_{m-1,1},\ldots,x_{m-1,2^{m-2}}$ are the leafs of the subtree under the path $b_mb_{m-1}$. For example, if $b_mb_{m-1}=10$, the variables $x_{m-1,1},\ldots,x_{m-1,2^{m-2}}$ are equal to $x_{m,1}=s_{2^{m-1}+1},\ldots,\allowbreak x_{m,2^{m-2}}=s_{2^{m-1}+2^{m-2}}$, which are the leafs of the subtree under the path 10 as depicted below.
\begin{center}
\begin{tiny}\begin{tikzpicture}
[n/.style={draw=none},
 every node/.append style={inner ysep=+0pt,outer ysep=+0pt,minimum size=+0pt}]
\Tree 
    [.{}
        \edge node[auto=right] {\small 0};
        [.{}
            \edge node[auto=right] {\small 0};
            \qroof{\parbox{\widthof{$s_{2^{m-1}+2^{m-2}+1}\cdots s_{2^{m}}$}}{\vspace*{.1cm}$s_1$\hfill$\cdots$\hfill$s_{2^{m-2}}$}}.{}
            \edge node[auto=left] {\small 1};
            \qroof{\parbox{\widthof{$s_{2^{m-1}+2^{m-2}+1}\cdots s_{2^{m}}$}}{\vspace*{.1cm}$s_{2^{m-2}+1}$\hfill$\cdots$\hfill$s_{2^{m-1}}$}}.{}
        ]
        \edge node[auto=left] {\small 1};
        [.{}
            \edge node[auto=right] {\small 0};
            \qroof{\parbox{\widthof{$s_{2^{m-1}+2^{m-2}+1}\cdots s_{2^{m}}$}}{\vspace*{.1cm}$s_{2^{m-1}+1}\cdots s_{2^{m-1}+2^{m-2}}$}}.{}
            \edge node[auto=left] {\small 1}; 
            \qroof{\parbox{\widthof{$s_{2^{m-1}+2^{m-2}+1}\cdots s_{2^{m}}$}}{\vspace*{.1cm}$s_{2^{m-1}+2^{m-2}+1}\cdots s_{2^{m}}$}}.{}
        ]
    ]
\end{tikzpicture}\end{tiny}
\end{center}

In general, the variables $x_{\ell,1},\ldots,x_{\ell,2^{\ell-1}}$ are equal to the leafs $s_{\sfleft},\ldots,\allowbreak s_{\sfright}$ under the path $b_m\cdots b_\ell$, where $\sfleft=\sum_{i=\ell}^m b_i 2^{i-1}+1$ and $\sfright=\sfleft+2^{\ell-1}-1$. 
Therefore, for $\ell=1$ equation (\ref{eq-log-2}) says that the variable $x_{1,1}$ is equal to the leaf $s_{\sfleft}=s_{\sfright}=s_\alpha$, since $\sfleft=\sfright=\sum_{i=1}^m b_i2^{i-1}+1=\alpha$, which is the unique leaf (and the unique node) in the subtree under the path $b_m\cdots b_1$.

Similarly as in Chandran et al.'s proof, for each new variable a new commitment must be added to the proof. But, in contrast with Chandran et al.'s proof, in this case the additional commitments do increase the asymptotic size of the proof. Indeed, the total number of new variables is \(2^{m-1}+2^{m-2}+\ldots+1=2^m-1=t-1\), and thus $t-1$ new commitments must be added.

One can reduce the total size of the commitments using the length reducing Multi-Pedersen commitments from Section~\ref{sec:ext-mp}. However, this must be done carefully in order to be able to express equation (\ref{eq-log-2}) with a Groth-Sahai proof of an equation that involves the MP commitments and the variables $b_1,\ldots,b_m$. For example, if one computes a single commitment to all variables $\MP.\Com_{ck}((x_{1,1},\ldots,x_{m,2^{m-1}})^\top;r)$ it is not clear how to obtain $b_\ell\MP.\Com_{ck}(\allowbreak (x_{\ell+1,1},\ldots,x_{\ell+1,2^\ell})^\top\allowbreak ;r_\ell)=\MP.\Com_{ck}(b_\ell(x_{\ell+1,1},\ldots,x_{\ell+1,2^\ell})^\top;b_\ell r_\ell)$. Our solution is to compute a single MP commitment to each vector that appears in equation (\ref{eq-log-2}) in order to show with Groth-Sahai proofs that
\begin{small}
\begin{align*}
\MP.\Com_{ck_\ell}\left(
                    \pmatri{x_{\ell,1}\\\vdots\\x_{\ell,2^{\ell-1}}};r_\ell\right)
=\ &(1-b_\ell)\MP.\Com_{ck_\ell}\left(\pmatri{x_{\ell+1,1}\\\vdots\\x_{\ell+1,2^{\ell-1}}};r_{\ell,1}\right)+\\
& b_\ell\MP.\Com_{ck_\ell}\left(\pmatri{x_{\ell+1,2^{\ell-1}+1}\\\vdots\\x_{\ell+1,2^\ell}};r_{\ell,2}\right)+\\
& \MP.\Com_{ck_\ell}(\vecb{0};y_\ell),
\end{align*}\end{small}
for some $y_\ell\in\Z_q$. In this way, we only need $3m=3\log t$ additional commitments. The reason for using different commitment keys will be clear when we explain soundness.

Concretely, the prover computes
\begin{align*}
&[\vecb{c}_\ell]_1=\MP.\Com_{ck_m}((x_{\ell,1},\ldots,x_{1,2^{\ell-1}})^\top;r_\ell),\\
\end{align*}
for random $r_\ell\in\Z_q$ and $\ell\in[m]$, and 
\begin{align*}
&[\vecb{c}_{\ell,1}]_1=\MP.\Com_{ck_{\ell}}((x_{\ell+1,1},\ldots,x_{\ell+1,2^{\ell-1}})^\top;r_{\ell,1}),\\
&[\vecb{c}_{\ell,2}]_1=\MP.\Com_{ck_{\ell}}((x_{\ell+1,2^{m-1}+1},\ldots,x_{\ell+1,2^\ell})^\top;r_{\ell,2}),\\
\end{align*}
for random $r_{\ell,1},r_{\ell,2}\in\Z_q$ and $\ell\in[m-1]$. Note that the prover does not need to compute commitments to $(x_{m+1,1},\ldots,x_{m+1,2^m})^\top$ since they can be computed by the verifier.

Then, the prover shows the satisfiability of equation (\ref{eq-log-2}) with a GS proof of
the satisfiability of
\begin{align}
&[\vecb{c}_\ell]_1-(1-b_\ell)[\vecb{c}_{\ell,1}]_1-b_\ell[\vecb{c}_{\ell,2}]_1 = y_\ell[\vecb{g}_{\ell,2^{\ell-1}+1}]_1, \text{ for } \ell \in[m],  \label{eq-log-5}
\end{align}
where $[\vecb{c}_{m,1}]:=\MP.\Com_{ck_m}((s_1,\ldots,s_{2^{m-1}})^\top;0)$ and $[\vecb{c}_{m,2}]:=\allowbreak \MP.\Com_{ck_m}(\allowbreak (s_{2^{m-1}+1},\allowbreak\ldots,s_{2^m})^\top;0)$ can be directly computed by the verifier, and $y_\ell:=r_\ell-(1-b_\ell)r_{\ell,1}-b_\ell r_{\ell,2}$.

The prover also shows that equation (\ref{eq-log-3}) is satisfied with a QA-NIZK proof that
\begin{equation}
[\vecb{c}]_1\text{ and }[\vecb{c}_1]_1\text{ open to the same value}, \label{eq-log-6}
\end{equation}
using the proof system from Section \ref{sec:aggcommit}.

Note that variables $x_{\ell+1,1},\ldots,x_{\ell+1,2^{\ell-1}}$ appear in both $[\vecb{c}_{\ell,1}]_1$ and $[\vecb{c}_{\ell+1}]_1$, as well as $x_{\ell+1,2^{\ell-1}+1},\ldots,x_{\ell+1,t/2^\ell}$ appear in both $[\vecb{c}_{\ell,2}]_1$ and $[\vecb{c}_{\ell+1}]_1$. To get a sound proof, the prover needs to show that this redundancy is consistent. That is, the prover needs to show that $[\vecb{c}_{\ell,1}]_1$ and $[\vecb{c}_{\ell,2}]_1$ are commitments to the first and last halves of the opening of $[\vecb{c}_{\ell+1}]_1$.

For \(\ell\in[m]\), let \(ck_\ell:=([\matr{G}_\ell]_1,\allowbreak[\vecb{g}_{\ell,2^{\ell-1}+1}]_1)\in\GG_1^{2\times{2^{\ell-1}+1}}\) the commitment key of a MP commitment scheme and let
\begin{align*}
&\matr{G}_{\ell,1}:=
\begin{pmatrix}
    \vecb{g}_{\ell,1}&\cdots&\vecb{g}_{i,2^{\ell-2}}
\end{pmatrix},
&\matr{G}_{\ell,2}:=
\begin{pmatrix}
    \vecb{g}_{\ell,2^{\ell-2}+1}&\cdots&\vecb{g}_{\ell,2^{\ell-1}}
\end{pmatrix}\\
&\matr{G}_\ell:=\matr{G}_{\ell,1}||\matr{G}_{\ell,2}
\end{align*}
To prove consistency the prover will show that, for each $\ell\in [m-1]$, the following linear system is satisfied
{\begin{align}
&\begin{pmatrix}
\vecb{c}_{\ell+1}\\
\vecb{c}_{\ell,1}\\
\vecb{c}_{\ell,2}
\end{pmatrix}
=
&\left(\begin{array}{cc|ccc}
\matr{G}_{\ell+1,1}           & \matr{G}_{\ell+1,2}            & \vecb{g}_{\ell+1,2^\ell+1} & \vecb{0}                     & \vecb{0}\\
\matr{G}_{\ell}               & \matr{0}_{2\times2^{\ell-1}}   & \vecb{0}                   & \vecb{g}_{\ell,2^{\ell-1}+1} & \vecb{0} \\
\matr{0}_{2\times 2^{\ell-1}} & \matr{G}_{\ell}                & \vecb{0}                   & \vecb{0}                     & \vecb{g}_{\ell,2^{\ell-1}+1}
\end{array}\right)
\vecb{w},\label{eq-log-split}
\end{align}}%
for some \(\vecb{w}\in\Z_q^{2^\ell+3}\), which can be proven using the proof system from Section \ref{sec:concat}.

Intuitively, \(\vecb{w}\) should be equal to \((x_{\ell+1,1},\ldots,x_{\ell+1,2^{\ell}},\allowbreak r_{\ell+1},r_{\ell,1},r_{\ell,2})\) and thus 
\begin{align*}
&[\vecb{c}_{\ell,1}]_1=\MP.\Com_{ck_\ell}(\allowbreak(x_{\ell+1,1},\ldots,x_{\ell+1,2^{\ell-1}})^\top;r_{\ell,1})\text{ and }\\
&[\vecb{c}_{\ell,2}]_1=\MP.\Com_{ck_\ell}((x_{\ell+1,2^{\ell-1}+1},\ldots, x_{\ell+1,2^{\ell}})^\top;r_{\ell,2}).
\end{align*}
However, since Multi-Pedersen commitments have multiple openings it might be the case that the satisfying witness of the proof is different from \((x_{\ell+1,1},\ldots,\allowbreak x_{\ell+1,2^\ell},r_{\ell+1},r_{\ell,1},r_{\ell,2})\) and thus the intuitive reasoning is invalid.

Despite this flawed reasoning, we will show that the proof system is still sound.

\subsubsection{Soundness Intuition}
Suppose that an adversary against soundness outputs GS commitments to \(b_1,\ldots,b_{m}\in\Z_q\), outputs commitments \([\vecb{c}_\ell]_1\), $\ell\in[m]$, and \([\vecb{c}_{\ell,1}]_1,[\vecb{c}_{\ell,2}]\), $\ell\in[m-1]$, a GS proofs of the satisfiability of equation (\ref{eq-log-5}), and QA-NIZK proofs of (\ref{eq-log-6}) and (\ref{eq-log-split}) for each \(\ell\in[m-1]\).
We will simply assume that \(b_1,\ldots,b_m\in\bits\), since it can be proven (with perfect soundness) with a GS proof of size \(\Theta(\log \setsize )\) or using the more efficient proofs of Section~\ref{sec:bits} (with computational soundness).

Let $\alpha_\ell:=(\alpha-1 \mod 2^{\ell-1})+1$, the position of $s_\alpha$ respective to the leafs under the path $b_m\cdots b_\ell$, and note that $\alpha_\ell \in[2^{\ell-1}]$.
In the reduction we will guess the (sub-)path $b_{m-1}\cdots b_1$ (it will be not necessary to guess first the edge of the path) chosen by the adversary, and for each $\ell\in[m]$, we will chose $\vecb{g}_{\ell,\alpha_\ell}$ linearly independent from the other $2^{\ell-1}$ vectors in $ck_\ell$. This can be done choosing  random $b'_{m-1},\ldots, b'_1\in\bits$ and aborting if the paths $b'_{m-1}\cdots b'_{1}$ and $b_{m-1}\cdots b_1$ are distinct. Therefore, our security reduction will have a security loss factor of $1/2^{m-1}=2/\setsize$. We sample $ck_\ell\gets\distlin_1^{2^{\ell-1},\alpha_\ell}$, as defined on Section \ref{sec:mddh}, which implies that for every $\ell\in[m]$ there exists unique $\tilde{x}_{\ell},\tilde{r}_\ell\in\Z_q$ such that $\vecb{c}_\ell:=\tilde{x}_\ell\vecb{g}_{\ell,\alpha_\ell}+\tilde{r}_\ell\vecb{g}_{\ell,2^{\ell-1}+1}$.

It will be useful to prove the next lemma about $\alpha_\ell$.
\begin{lemma} Let $b_m,\ldots,b_1\in\bits$. For all $\ell\in[m]$, $\alpha_\ell = \alpha-\sfleft+1$ and, for all $\ell\in[m-1]$, $\alpha_{\ell+1}=\alpha_{\ell}+b_\ell2^{\ell-1}$.
\label{lemma:alpha}
\end{lemma}
\begin{proof}
Recall that $\sfleft=\sum_{i=\ell}^m b_i2^{i-1}+1$ is the index of the leftmost leaf under the path $b_m\cdots b_\ell$. It holds that
\begin{align*}
\alpha_\ell-1 &= \sum_{i=1}^m b_i2^{i-1} \mod 2^{\ell-1}\\
              &= \sum_{i=\ell}^m b_i 2^{i-1} + \sum_{i=1}^{\ell-1}b_i2^{i-1} \mod 2^{\ell-1}\\
              &= \sum_{i=1}^{\ell-1}b_i2^{i-1}\\
              &= \sum_{i=1}^m b_i2^{i-1} - \sfleft\\
              &= \alpha-\sfleft\\
&\Longleftrightarrow \alpha_\ell=\alpha-\sfleft+1.
\end{align*}
On the other hand
\begin{align*}
\alpha_{\ell+1}-1 &= \alpha-1 \mod 2^\ell\\
&= \sum_{i=1}^{\ell} b_i2^{i-1}\\
&= b_\ell2^{\ell-1}+\sum_{i=1}^{\ell-1}b_i 2^{i-1}\\
&= b_\ell2^{\ell-1} + (\alpha-1 \mod 2^{\ell-1})\\
&\Longleftrightarrow \alpha_{\ell+1}=\alpha_\ell+b_\ell2^{\ell-1}
\end{align*}
\end{proof}

We prove by induction on \(\ell\) that \(\vecb{c}_\ell= s_\alpha\vecb{g}_{\ell,\alpha_\ell}+\tilde{r}_{\ell}\vecb{g}_{\ell,\setsize /2^\ell+1}\), for some $\tilde{r}_\ell\in\Z_q$. If this is the case $\vecb{c}_1=s_\alpha\vecb{g}_{1,1}+\tilde{r}_{1}\vecb{g}_{1,2}$. Soundness of proof (\ref{eq-log-6}) together with the fact that \(ck_1\) is perfectly binding implies that \(x=\tilde{x}_{1}=s_{\alpha}\in S\) which proves soundness.

In the base case ($\ell=m$), equation (\ref{eq-log-5}) and the fact that \(\vecb{g}_{m,i}\in\Span(\vecb{g}_{m,2^{m-1}+1})\) if \(i\neq \alpha_\ell\) together with Lemma \ref{lemma:alpha} implies that 
\begin{align*}
\vecb{c}_m &= (1-b_m)\sum_{i=1}^{2^{m-1}}s_i \vecb{g}_{m,i}+b_m\sum_{i=1}^{2^{m-1}}s_{i+2^{m-1}}\vecb{g}_{m,i}\\
&= (1-b_m)s_{\alpha_\ell}\vecb{g}_{m,\alpha_\ell} +b_ms_{\alpha_\ell+2^{m-1}}\vecb{g}_{m,\alpha_\ell}+\tilde{r}_1\vecb{g}_{m,2^{m-1}+1}\\
&= (1-b_m)s_{\alpha-\sfleft+1}\vecb{g}_{m,\alpha_\ell} +b_ms_{\alpha-\sfleft+1+2^{m-1}}\vecb{g}_{m,\alpha_\ell}+\tilde{r}_1\vecb{g}_{m,2^{m-1}+1}\\
&=\begin{cases}
    s_{\alpha-1+1}\vecb{g}_{1,\alpha_\ell}+\tilde{r}_1\vecb{g}_{1,t/2} & \text{ if } b_m=0 \ (\text{and thus }\sfleft=1) \\
    s_{\alpha-(2^{\ell-1}+1)+1+2^{\ell-1}}\vecb{g}_{1,\alpha_\ell}+\tilde{r}_1\vecb{g}_{1,t/2} & \text{ if } b_m=1 \ (\text{and thus }\sfleft=2^{\ell-1}+1) 
\end{cases}
\end{align*}
for some \(\tilde{r}_1\in\Z_q\). In both cases $\vecb{c}_1=s_\alpha\vecb{g}_{1,\alpha_\ell}+\tilde{r}_1\vecb{g}_{1,t/2}$.

In the inductive case we assume that \(\vecb{c}_{\ell+1}=s_{\alpha}\vecb{g}_{\ell+1,\alpha_{\ell+1}}+\tilde{r}_{\ell+1}\vecb{g}_{\ell+1,2^\ell+1}\) and we want to show that $\vecb{c}_\ell = s_\alpha\vecb{g}_{\ell,\alpha_\ell}+\tilde{r}_\ell\vecb{g}_{\ell,2^{\ell-1}+1}$. Since \(\vecb{g}_{\ell+1,\alpha_{\ell+1}}\) is linearly independent from the rest of vectors in \(ck_{\ell+1}\), any solution to equation (\ref{eq-log-split}) is equal to \(s_{\alpha}\) at position \(\alpha_{\ell+1}=\alpha_\ell+b_\ell2^{\ell-1}\) as depicted below.
\begin{align*}
\pmatri{\vecb{c}_{\ell+1}\\\vecb{c}_{\ell,1}\\\vecb{c}_{\ell,2}}=
\pmatri{
\cdots & \vecb{g}_{\ell+1,\alpha_\ell} & \cdots  & \vecb{g}_{\ell+1,\alpha_\ell+2^{\ell-1}} & \cdots\\
\cdots & \vecb{g}_{\ell,\alpha_\ell}     & \cdots  & \vecb{0}                           & \cdots\\
\cdots & \vecb{0}                        & \cdots  & \vecb{g}_{\ell,\alpha_\ell}        & \cdots
}
\pmatri{\vdots\\s_\alpha\\\vdots}
\end{align*}
If $b_{\ell}=0$, by Lemma \ref{lemma:alpha}, $\alpha_{\ell+1}=\alpha_\ell$. Therefore, any solution to equation (\ref{eq-log-split}) is equal to $s_\alpha$ at position $\alpha_\ell$ and thus $\vecb{c}_{\ell,1} = s_\alpha\vecb{g}_{\ell,\alpha_\ell}+\tilde{r}_{\ell,1}\vecb{g}_{\ell,t/2^\ell+1}$.
Equation \ref{eq-log-5} implies that
\begin{align*}
\vecb{c}_{\ell}=&(1-b_\ell)(s_\alpha\vecb{g}_{\ell,\alpha_\ell}+\tilde{r}_{\ell,1}\vecb{g}_{\ell,t/2^\ell})+b_\ell\vecb{c}_{\ell,2}+y_\ell\vecb{g}_{\ell,t/2^\ell+1}\\
               =& s_\alpha\vecb{g}_{\ell,\alpha_\ell}+(\tilde{r}_{\ell,1}+y_\ell)\vecb{g}_{\ell,t/2^\ell+1}.
\end{align*}
If $b_{\ell}=1$, then $\alpha_{\ell+1}=\alpha_\ell+2^{\ell-1}$ and similarly, $\vecb{c}_{\ell}=s_\alpha\vecb{g}_{\ell,\alpha_\ell}+(\tilde{r}_{\ell,2}+y_\ell)\vecb{g}_{\ell,t/2^\ell}$.

\subsection{The Aggregated Case} \label{sec:log-set-memb-Z}
Let $\setsize:=|S|$ and \(m:=\log \setsize \). The statement is now \([\grkb{\zeta}_1]=\GS.\Com_{ck}(x_1;r_1),\ldots,\allowbreak[\grkb{\zeta}_n]_1=\GS.\Com_{ck}(x_n;r_n)\), for some $n\in\mathbb{N}$, and the prover wants to show that \(x_i=s_{\alpha_i}\), for all \(i\in[n]\) and \(\alpha_i=\sum_{j=1}^m b_{i,j}2^m+1\), for some $b_{i,1},\ldots,b_{i,m}\in\bits$. We need reformulate equations (\ref{eq-log-2}) and (\ref{eq-log-3}) to take in count new variables. For \(\ell\in [m],j\in[n]\), define
\begin{align*}
&\vecb{x}_j^\ell:=
\begin{pmatrix}
\vecb{x}^\ell_{1,j}\\
\hline
\vecb{x}^\ell_{2,j}
\end{pmatrix}
:=
\begin{pmatrix}
x^\ell_{1,j}\\\vdots\\x^\ell_{\setsize ^{\ell+1},j}\\
\hline
x^\ell_{\setsize /2^{\ell+1}+1,j}\\\vdots\\x^\ell_{\setsize /2^\ell,j}
\end{pmatrix},
&\vecb{b}_\ell := 
\begin{pmatrix}
b_{1,\ell}\\\vdots\\b_{n,\ell}
\end{pmatrix},\\
&\vecb{x}_{1,j}^0 := \begin{pmatrix}
s_1\\\vdots\\s_{\setsize /2}
\end{pmatrix},\text{ and }
&\vecb{x}_{2,j}^0 := \begin{pmatrix}
s_{\setsize /2+1}\\\vdots\\s_{\setsize }
\end{pmatrix},
\end{align*}
and define new equations for each $\ell\in[m],j\in[m]$
\begin{align}
&\vecb{x}^\ell_j=\vecb{x}^{\ell-1}_{1,j}({1}-{b}_{j,\ell})+\vecb{x}^{\ell-1}_{2,j}{b}_{j,\ell},\label{eq-alog-1}\\
&x_j= \vecb{x}_{j}^m\label{eq-alog-1}
\end{align}

Next, we construct a QA-NIZK proof system for the language
\(
\Lang_{ck,\mathsf{set}}^n
\)
and in Section~\ref{sec:improved-aZKSMP-group-case} we show how to extend these ideas to show membership in the language
\(
\Lang_{ck,S}^n\)
for any \(S\subset\GG_1\), as defined at the beginning of this chapter.
The construction follows the intuition outlined before but it ``aggregates'' many instances on a single \(\Theta(\log \setsize )\) proof. From a high level this is done as follows:
\begin{itemize}
\item Given that now there are \(n\) bit-strings of size \(m\), the binary representation of $\alpha_1,\ldots,\alpha_n$, they are ``shrinked'' into \(m\) Multi-Pedersen commitments whose commitment keys are \([\vecb{h}_1]_2,\ldots,[\vecb{h}_{n+1}]_2\). Thereby, the variables $b_{i,1},\ldots,b_{i,m}$, which form the binary representation of $\alpha_i$, will be contained in \(m\) coefficients of \([\vecb{h}_i]_2\) of the $m$ Multi-Pedersen commitments to $\vecb{b}_1,\ldots,\vecb{b}_m$.
\item Commitments \([\vecb{c}_\ell]_1\) (we switched from index \(i\) to \(\ell\)) from the intuition, which contain the \(\setsize /2^\ell\) elements from \(S\) whose index prefix is \((b_1\cdots b_{\ell})\), should now contain \(n\setsize /2^\ell\) elements. Consequently, the commitment key \(ck_\ell\) is enlarged so that is able to contain the extra elements, and the coefficients of the elements from \(i\) th proof, \( i\in [n]\), are the ones from \([\vecb{g}_{i,1}^\ell]_1,\ldots,[\vecb{g}_{i,\setsize /2^\ell}^\ell]_1\).
\item Equation (\ref{eq-log-split}) is proven in the same way, enlarging the matrix as consequence of the enlargement of commitment keys.
\item Equations (\ref{eq-log-4}) and (\ref{eq-log-5}) are no longer proven using GS proofs, but using similar techniques as the ones from Chapter \ref{sec:bits}. We will have commitments whose discrete logs can be written as linear combinations of \(\vecb{g}_{i,1}^\ell,\ldots,\vecb{g}_{n,\setsize /2^\ell}^\ell\) and \(\vecb{h}_1,\ldots,\vecb{h}_{n+1}\). If we re-write equations (\ref{eq-log-4}) and (\ref{eq-log-5}) replacing \(b's\) with commitments and multiplication with the \emph{kronecker product} (that is, \(\vecb{x}\vecb{y}^\top\)), we will obtain an expression which at certain coefficients of \(\vecb{g}_{i,k}^\ell\vecb{h}_j^\top\) contains what we want and at others contains ``junk''. Similarly as done in Chapter \ref{sec:bits}, we will add two matrices \(\matr{\Theta}_\ell\) and \(\matr{\Pi}_\ell\) which will ``contain'' this junk and will help to balance the equation. It is only left to show that these new matrices are in the appropriate subspace and thus, they do not alter the equations we want to show to hold.
\item Soundness is proven in the same fashion as in the protocols from Chapter \ref{sec:shuf-rp}. That is, we guess one index \(j^*\in[n]\) such that \(x_{j^*}\notin S\) and choose the commitment keys in such a way that, at coordinate \(j^*\), the same equations of the non-aggregated case holds. This will imply that we lose an additional factor of \(1/n\) in the reduction and thus, the total security lost is a factor \(\frac{2}{n\setsize }\).
\end{itemize}
\subsubsection{The Scheme}

\begin{description}

\item[{\(\algK_1(\gk, ck)\)}:]
For each \(\ell\in [m]\) let \(\matr{G}^\ell:=\matr{G}^\ell_1||\cdots||\matr{G}^\ell_n||\vecb{g}^\ell_{n\setsize /2^\ell+1}\gets\distlin_1^{n\setsize /2^\ell,0}\), where
\[\matr{G}^\ell_i=
(\matr{G}^\ell_{i,1}|\matr{G}^\ell_{i,2})
=
(\vecb{g}^\ell_{i,1}\cdots\vecb{g}^\ell_{i,\setsize /2^{\ell+1}}|\vecb{g}^\ell_{i,\setsize /2^{\ell+1}+1}\cdots\vecb{g}^\ell_{i,\setsize /2^\ell})
\in\Z_q^{2\times\setsize /2^\ell},\] \(i\in  [n]\), and define \(ck_\ell:=[\matr{G}^\ell]_1\).
Let \(\matr{H}=\begin{pmatrix}\vecb{h}_1&\cdots&\vecb{h}_n&\vecb{h}_{n+1}\end{pmatrix}\gets\distlin_1^{n,0}\) and define \(ck':=[\matr{H}]_2\). 

Pick \(\matr{T}\gets\Z_q^{2\times 2}\) and for each \(\ell\in[m]\), \( i_1\in [n]\), \(i_2 \in [\setsize /2^\ell]\), \(j\in  [n+1]\), such that \(i_1\neq j\) or, \(i:=(i_1-1)\setsize /2^\ell+i_2=n\setsize /2^\ell+1\) and \(j=n+1\) define matrices
\[\matr{M}^\ell_{i,j}:=([\matr{C}_{i,j}^\ell]_1,[\matr{D}_{i,j}^\ell]_2):=([\vecb{g}_{i_1,i_2}^\ell\vecb{h}_j^{\top}+\matr{T}]_1,[-\matr{T}]_2),\]
For \(\ell\in [m]\) let \(\mathcal{M}_\ell\subset\GG_1^{2\times 2}\times\GG_2^{2\times 2}\) the set of the matrices \(\matr{M}\) whose super-index is \(\ell\) and define \(\mathcal{C}_\ell\subset\Z_q^{2\times 2}\) the set of matrices \(\matr{C}\) whose super-index is \(\ell\).

Let \(\Pi_\sfsum\) be the proof system for Sum in Subspace 
(Section~\ref{sec:sum}), \(\Pi_\mathsf{lin}\) the proof system for membership in linear subspaces from Section~\ref{sect:QANIZKlinspace}, \(\Pi_\sfbits\) the proof system for proving that many commitments open to bit-strings from section \ref{sec:matr-bits}, and \(\Pi_\sfcom\)
be an instance of the proof system for equal commitment opening (Section~\ref{sec:aggcommit}).

For each $\ell\in[m]$, let
\(\crs_{\sfsum,\ell} \gets \Pi_\sfsum.\algK_1(\gk, \mathcal{M}_\ell)\).\footnote{We identify
matrices in \(\GG_1^{2 \times 2}\) (respectively in \(\GG_2^{2 \times 2}\)) with vectors in \(\GG_1^{4}\) (resp. in \(\GG_2^{4}\)).}, let \(\crs_{\mathsf{lin},\ell}\gets \Pi_\mathsf{lin}.\algK_1(gk;\allowbreak[\matr{G}^\ell_{\mathsf{split}}]_1,n\setsize /2^{\ell}+3)\), let \(\crs_\sfbits\gets\Pi_\sfbits.\algK_1(gk,[\matr{H}]_2,m)\), and let \(\crs_\sfcom \gets \Pi_\sfcom.\algK_1(\gk, \bmatr{G}_1,\bmatr{H}_2,m)\), where
\[
\matr{G}_\mathsf{split}^\ell:=
\begin{pmatrix}
\matr{G}^{\ell}_{1,1} & \matr{G}^{\ell}_{1,2} & \cdots & \matr{G}^{\ell}_{n,1} & \matr{G}^{\ell}_{n,2} & \vecb{g}^{\ell}_{n\setsize /2^{\ell}+1} & \matr{0}                       & \matr{0}\\
\matr{G}^{\ell+1}_{1} & \matr{0}           & \cdots & \matr{G}^{\ell+1}_{n} & \matr{0}           & \matr{0}                    &\vecb{g}^{\ell+1}_{n\setsize /2^{\ell+1}+1} & \matr{0}\\
\matr{0}           & \matr{G}^{\ell+1}_{1} & \cdots & \matr{0}           & \matr{G}^{\ell+1}_{n} & \matr{0}                    & \matr{0}                       & \vecb{g}^{\ell+1}_{n\setsize /2^{\ell+1}+1}
\end{pmatrix}.
\]
The common reference string is given by:
\begin{eqnarray*}
\mathsf{crs}&:=&\left( gk, [\matr{G}]_1,
    [\matr{H}]_2, \{\mathcal{M}_\ell,\crs_{\sfsum,\ell},\crs_{\mathsf{lin},\ell}:\ell\in [m]\},\crs_\sfbits,\crs_\sfcom \right).
 \end{eqnarray*}


\item[{\(\algP(\mathsf{crs}, ([\grkb{\zeta}_1]_1, \ldots, [\grkb{\zeta}_n]_1,S), \langle (x_1,\ldots,x_n),(w_1,\ldots,w_n) \rangle)\)}:]
The prover compute commitments
\begin{align*}
&[\vecb{c}_\ell]_1:=\MP.\Com_{ck_\ell}({\vecb{x}^\ell_1}^\top,\ldots,{\vecb{x}^\ell_n}^\top;r_\ell), \text{ for } \ell \in [m],\\
&[\vecb{c}_{\ell,1}]_1:=\MP.\Com_{ck_\ell}({\vecb{x}^{\ell-1}_{1,1}}^\top,\ldots,{\vecb{x}^{\ell-1}_{1,n}}^\top;r_{1,\ell}),\\
&[\vecb{c}_{\ell,2}]_1:=\MP.\Com_{ck_\ell}({\vecb{x}^{\ell-1}_{2,1}}^\top,\ldots,{\vecb{x}^{\ell-1}_{2,n}}^\top;r_{2,\ell}), \text{ for } 1<\ell\leq m\\
&[\vecb{d}_\ell]_2:=\MP.\Com_{ck'}(\vecb{b}_\ell;t_\ell),\text{ for } i\in[m]
\end{align*}
 where \(r_\ell,r_{\ell,1},r_{\ell,2},t_j\gets\Z_q\) and the variables \(x^\ell_{j,\ell}\) are the ones defined in equation (\ref{eq-alog-1}). The prover computes a proof \(\pi_\sfbits\) that \([\vecb{d}_1]_2,\ldots,[\vecb{d}_m]_2\) open to bit-strings. Then, for \(\ell\in [m]\), the prover pick matrices \(\matr{R}_\ell\gets\Z_q^{2\times 2}\), computes
\begin{align*}
([\matr{\Theta}_\ell]_1,[\matr{\Pi}_\ell]_2)  := & \sum_{i=1}^n\sum_{j\neq i}\sum_{k=1}^{\setsize /2^\ell}(x^\ell_{k,i}-x^{\ell-1}_{k,i}(1-b_{j,\ell})-x^{\ell-1}_{\setsize /2^\ell+k,j}b_{j,\ell})\matr{M}_{(i-1)\setsize /2^\ell+k,j}^\ell\\
&+ \sum_{i=1}^n\sum_{k=1}^{\setsize /2^\ell}t_\ell(x^{\ell-1}_{k,i}-x^{\ell-1}_{\setsize /2^{\ell}+k,i})\matr{M}_{(i-1)\setsize /2^\ell+k,n+1}^\ell \\
&+ \sum_{j=1}^n (r_\ell-r_{1,\ell}(1-b_{j,\ell})-r_{2,\ell}b_{j,\ell})\matr{M}_{n\setsize /2^\ell+1,j}^\ell \\
&+(r_{1,\ell}-r_{2,\ell})t_\ell\matr{M}^\ell_{n\setsize /2^\ell+1,n+1}+([\matr{R}_\ell]_1,[-\matr{R}_\ell]_2),
\end{align*}
where \(r_{1,1}=r_{2,1}=0\), and computes proofs that
\begin{align*}
&\begin{pmatrix}
\vecb{c}_{\ell}\\\vecb{c}_{\ell+1,1}\\\vecb{c}_{\ell+1,2}
\end{pmatrix}\in
\Span(\matr{G}^{\ell}_\mathsf{split})\ (\text{ if }\ell< m), &\matr{\Theta_\ell}+\matr{\Pi_\ell}\in\Span(\mathcal{C}_\ell).
\end{align*}
Finally, it computes a proof \(\pi_\sfcom\) that \(([\grkb{\zeta}_1]_1,\ldots,[\grkb{\zeta}_n]_1)\) and \([\vecb{c}_m]_1\) open to the same value.

The proof is \(\pi:=(\{([\vecb{c}_\ell]_1,[\vecb{c}_{\ell,1}]_1,[\vecb{c}_{\ell,2}]_1,[\vecb{d}_\ell]_2,[\matr{\Theta}_\ell]_1,[\matr{\Pi}_\ell]_2,\pi_{\mathsf{lin},\ell},\pi_{\sfsum,\ell}):\ell\in [m]\},\pi_\sfbits,\pi_\sfcom)\).

\item[{\(\algV(\crs,([\grkb{\zeta}_1]_1, \ldots, [\grkb{\zeta}_n]_1,S),\pi)\)}:]
Let \([\vecb{c}_{1,1}]_1:=\MP.\Com_{ck_1}(s_1,\ldots,s_{\setsize /2};0),[\vecb{c}_{1,2}]:=\MP.\Com_{ck_1}(s_{\setsize /2+1},\ldots,s_{\setsize };0)\). The verifier checks the validity of \(\pi_\sfbits,\pi_\sfcom\) 
and, for each \(\ell\in [m]\), checks the validity of \(\pi_{\mathsf{lin},\ell},\pi_{\sfsum,\ell}\) and of equations
\begin{align}
&[\vecb{c}_\ell]_1\left(\sum_{j=1}^n [\vecb{h}_j]_2\right)^\top-
[\vecb{c}_{\ell,1}]_1\left(\sum_{j=1}^n[\vecb{h}_j]_2-[\vecb{d}_\ell]_2\right)^\top-
[\vecb{c}_{\ell,2}]_1[\vecb{d}_\ell]_2^\top = \nonumber\\
&[\matr{\Theta}_\ell]_1[\matr{I}]_2+[\matr{I}]_1[\matr{\Pi}_\ell]_2.  \label{eq-alog-5}
\end{align}

\item[{\(\mathsf{S}_1({gk},ck)\):}] The simulator receives as input a description of an asymmetric bilinear group \({gk}\) and a GS commitment key $ck$. It generates and outputs the CRS in the same way as \(\algK_1\), but additionally it also  outputs the simulation trapdoor 
\(\tau:=(\matr{H},\tau_\sfcom,\tau_\sfbits,\{\tau_{\sfsum,\ell},\tau_{\mathsf{lin},\ell}:\ell\in [m]\})\),
where \(\tau_{\sfsum},\tau_{\Psi_\sfbits},\tau_{\sfsum,\ell},\tau_{\mathsf{lin,\ell}}\) are, respectively, \({\Pi_\sfsum},{\Pi_\sfcom},\Pi_\sfsum,\Pi_\mathsf{lin}\) simulation trapdoors.

\item[{\(\mathsf{S}_2(\crs,([\grkb{\zeta}_1]_1,\ldots,[\grkb{\zeta}_n]_1,S),\tau)\):}] Define \(\vecb{x}^\ell_j:=\vecb{0}\) and \(\vecb{b}_\ell:=\vecb{0}\) for all \(\ell\in [m],j\in[n]\), and compute \([\vecb{c}_\ell]_1, [\vecb{c}_{\ell,1}]_1,[\vecb{c}_{\ell,2}]_1,[\vecb{d}_\ell]_2\) and \([\matr{\Theta}_\ell]_1,[\matr{\Pi}_\ell]_1\), as an honest prover would do (that is, with all variables set to 0).
Finally, simulate proofs \(\pi_\sfcom,\pi_\sfbits,\pi_{\sfsum,\ell},\pi_{\mathsf{lin},\ell}\) using the respective trapdoors.
\end{description}

We prove the following Theorem.

\begin{theorem} \label{theo:bits}
The proof system described above is a QA-NIZK proof system for the language \(\Lang_{ck,\mathsf{set}}^n\)
 with Perfect Completeness, Computational Soundness, and Perfect Zero-Knowledge.
\end{theorem}	

\subsubsection{Completeness}
Completeness follows from completeness of \(\Pi_\sfsum,\Pi_\mathsf{lin},\Pi_\sfbits,\Pi_\sfcom\), and from the fact that equation (\ref{eq-alog-5}) is satisfied for each \(\ell\in [m]\):
\begin{align*}
&\vecb{c}_\ell\left(\sum_{j=1}^n \vecb{h}_j\right)^\top-
\vecb{c}_{\ell,1}\left(\sum_{j=1}^n\vecb{h}_j-\vecb{d}_\ell\right)^\top-
\vecb{c}_{\ell,2}\vecb{d}_\ell^\top &= \\
&\sum_{i=1}^n\sum_{j=1}^n\matr{G}^\ell_i\vecb{x}^\ell_i\vecb{h}_j^\top+\sum_{j=1}^nr_\ell\vecb{g}_{n\setsize /2^\ell+1}^\ell\vecb{h}_j^\top
-\sum_{i=1}^n\sum_{j=1}^n\matr{G}^\ell_i\vecb{x}^{\ell-1}_{1,i}(1-b_{j,\ell})\vecb{h}_j^\top\\
&+\sum_{i=1}^n\matr{G}^\ell_i\vecb{x}^{\ell-1}_{1,i} t_\ell\vecb{h}_{n+1}^\top-\sum_{j=1}^nr_{1,\ell}\vecb{g}^\ell_{n\setsize /2^\ell+1}\vecb{h}_j^\top+ r_{1,\ell}t_\ell\vecb{g}^\ell_{n\setsize /2^\ell+1}\vecb{h}_{n+1}^\top\\
&-\sum_{i=1}^n\sum_{j=1}^n\matr{G}^\ell_i\vecb{x}^{\ell-1}_{2,i}b_{j,\ell}\vecb{h}_j^\top-\sum_{i=1}^n\matr{G}^\ell_i\vecb{x}^{\ell-1}_{2,i} t_\ell\vecb{h}_{n+1}^\top-\sum_{j=1}^nr_{2,\ell}\vecb{g}^\ell_{n\setsize /2^\ell+1}\vecb{h}_j^\top\\
&- r_{2,\ell}t_\ell\vecb{g}^\ell_{n\setsize /2^\ell+1}\vecb{h}_{n+1}^\top &=\\
&\sum_{i=1}^n\sum_{j\neq i}\matr{G}^\ell_i(\vecb{x}^\ell_i-(\vecb{x}^{\ell-1}_{1,i}(1-b_{j,\ell})+\vecb{x}^{\ell-1}_{2,1}b_{j,\ell}))\vecb{h}_j^\top+\\
&\sum_{i=1}^n\matr{G}^\ell_i(\vecb{x}^{\ell-1}_{1,i}-\vecb{x}^{\ell-1}_{2,i})t_\ell\vecb{h}_{n+1}^\top+\sum_{j=1}^n(r_\ell-r_{1,\ell}-r_{2,\ell})\vecb{g}_{n\setsize /2^\ell+1}^\ell\vecb{h}_{j}^\top\\
&+(r_{1,\ell}-r_{2,\ell})t_\ell\vecb{g}^\ell_{n\setsize /2^\ell+1}\vecb{h}_{n+1}^\top &=\\
&\sum_{i=1}^n\sum_{j\neq i}\sum_{k=1}^{\setsize /2^\ell}(x_{k,i}^\ell-(x_{k,i}^{\ell-1}(1-b_{j,\ell})+x_{\setsize /2^\ell+k,i}^{\ell-1}b_{j,\ell})))\vecb{g}_{(i-1)\setsize /2^\ell+k}^\ell\vecb{h}_j^\top\\
&+\sum_{i=1}^n\sum_{k=1}^{\setsize /2^\ell}t_\ell(x_{k,i}^{\ell-1}-x_{\setsize /2^\ell+k,i}^{\ell-1})\vecb{g}_{(i-1)\setsize /2^\ell+k}^\ell\vecb{h}_{n+1}^\top\\
&\sum_{j=1}^n(r_\ell-r_{1,\ell}-r_{2,\ell})\vecb{g}_{n\setsize /2^\ell+1}^\ell\vecb{h}_{j}^\top+(r_{1,\ell}-r_{2,\ell})t_\ell\vecb{g}^\ell_{n\setsize /2^\ell+1}\vecb{h}_{n+1}^\top &=\\
&\matr{\Theta}\matr{I}+\matr{I}\matr{\Pi}.
\end{align*}

\subsubsection{Soundness}

The following theorem guarantees Soundness. 
 
\begin{theorem} Let \(\mathsf{Adv}_{{\Pi_\sfset}}(\advA)\) 
be the advantage of an adversary \(\advA\) against the soundness of 
the proof system  described above. There exist PPT adversaries
\(\advD_1,\advD_2,\advB_\sfbits,\advB_\sfcom,\advB_\sfsum,\advB_\mathsf{lin}\) such that 
\begin{align*}
\mathsf{Adv}_{{\Pi_\sfset}}(\advA) \leq 
n \left(\right.
    &\mathsf{Adv}_{\mathcal{L}_1,\Gr}(\advD_1) 
        + \setsize /2\left(4/q
            +  \mathsf{Adv}_{\Pi_\sfbits}(\advB_\sfbits)
            +  \mathsf{Adv}_{\mathcal{L}_1,\Hr}(\advB_2)\right. \\
    &+ \left.\left.\mathsf{Adv}_{{\Pi_\sfcom}}(\advB_\sfcom)
        + m\mathsf{Adv}_{{\Pi_\sfsum}}(\advB_\sfsum)
        + m\mathsf{Adv}_{{\Pi_\mathsf{lin}}}(\advB_\mathsf{lin})\right)\right).
\end{align*}
\label{teo:bitstr-soundness}
\end{theorem}

The proof follows from the indistinguishability of the following games:
\begin{itemize}
\item[\(\mathsf{Real}\):] This is the real Soundness game. The output is 1 if the adversary submits some \(([\grkb{\zeta}_1]_1,\ldots,[\grkb{\zeta}_n]_1,S)\notin\Lang_{ck,\mathsf{set}}^n\) and the corresponding proof which is accepted by the verifier.
\item[\(\sfGame_0\):] This identical to \(\mathsf{Real}\), except that \(\algK_1\) does not receive \(ck\) as a input but
it samples \(ck\) itself together with its discrete logarithms.
\item[\(\sfGame_1\):] This game is identical to \(\sfGame_0\) except that now it chooses random \(j^*\in[n]\) and it aborts if \(x_{j^*}\notin S\).
\item[\(\sfGame_2\):] This game is identical to \(\sfGame_1\) except that now \(\matr{H}\gets\distlin^{n,j^*}_1\).
\item[\(\sfGame_3\):] This game is identical to \(\sfGame_2\) except that now it chooses \((b_2\cdots b_m)\gets \setsize /2\) (recall that \((b_1\cdots b_m)=\sum_{i=1}b_i2^{m-i}+1\)) and aborts if \((b_{j^*,1},\ldots,b_{j^*,m})\notin\bits^m\) or \((b_2\cdots b_m)\neq(b_{j^*,2}\cdots b_{j^*,m})\), where \(b_{j^*,2},\ldots,b_{j^*,m}\) are the openings of \([\vecb{d}_2]_2,\ldots,[\vecb{d}_m]_2\) at coordinate \(j^*\), respectively.
\item[\(\sfGame_4\):] This game is identical to \(\sfGame_3\) except that now \(\matr{G}^\ell\gets\distlin_1^{n\setsize /2^\ell,(j^*-1)\setsize /2^\ell+(b_{\ell+1}\cdots b_m)}\), for \(\ell\in [m]\).
\end{itemize}

It is obvious that the first two games are indistinguishable. The rest of the argument goes as follows.

\begin{lemma}
\(\Pr\left[ \mathsf{Game}_1(\advA)=1\right]\geq\dfrac{1}{n}\Pr\left[\mathsf{Game}_0(\advA)=1\right].\)
\end{lemma}

\begin{proof}  The probability that
 \(\mathsf{Game}_1(\advA)=1\) is the probability that  a) \(\mathsf{Game}_0(\advA)=1\) and
b)  \(x_{j^*} \notin S\). The view of adversary \(\advA\) is independent of \(j^*\), while, if \(\mathsf{Game_0}(\advA)=1\), then there is at least one index \(j \in [n]\) such that  
such that  \(x_{j} \notin S\). Thus, 
the probability that the event described in b) occurs conditioned on \(\mathsf{Game_0}(\advA)=1\), is greater than or equal to \(1/n\) and the lemma follows.
\end{proof}

\begin{lemma} There exists a\ \(\distlin_1\)-\(\mddh_{\GG_2}\) adversary \(\advD_2\) such that
\(|\Pr\left[\mathsf{Game}_{1}(\advA)=1\right]\linebreak-\Pr\left[\mathsf{Game}_{2}(\advA)=1\right]|\) \(\leq \mathsf{Adv}_{\distlin_1,\ggen_a}(\advD_2).\)
\end{lemma}
\begin{proof}
We construct an adversary \(\advD_2\) that receives 
a challenge \(([\vecb{a}]_2,[\vecb{u}]_2)\) of the 
\(\distlin_1\)-\(\mddh_{\GG_2}\) Assumption. From this challenge, \(\advD_2\) just defines the matrix  \([\matr{H}]_2\in\GG_2^{2\times(n+1)}\) as the matrix whose last column is \([\vecb{a}]_2\), the ith column is \([\vecb{u}]_2\), and the rest of the columns are random vectors in the image of \([\vecb{a}]_2\). 
Obviously, when \([\vecb{u}]_2\) is sampled from 
the image of \([\vecb{a}]_2,\) \(\matr{H}\) follows the distribution \(\distlinizeroone\), while if \([\vecb{u}]_2\) is a uniform element of \(\GG^2_2\), \(\matr{H}\) follows the distribution \(\distlin_1^{n,j^*}\). 
 
Adversary \(\advD_2\) samples
\(\matr{G}^\ell \gets \distlin_1^{n\setsize /2^\ell,0}\). Given that \(\advD_2\) does not know the discrete logarithms of \([\matr{H}]_2\), it cannot compute the pairs \((\matr{C}^\ell_{i,j},\matr{D}^\ell_{i,j})\) exactly as in \(\sfGame_0\). Nevertheless, for each \(i,j,\ell\) it can compute identically distributed pairs by picking \(\matr{T}\gets\Z_q^{2\times 2}\) and defining
\[
([\matr{C}^\ell_{i,j}]_1,[\matr{D}^\ell_{i,j}]_2):=([\matr{T}]_1,\vecb{g}_{i_1,i_2}^\ell[\vecb{h}_j]_2^\top-[\matr{T}]_2),
\]
where \(i=(i_1-1)\setsize /2^\ell+i_2\) for some \(1\leq i_1\leq n,1\leq i_2 \leq \setsize /2^\ell\).

The rest of the elements of the CRS are honestly computed. When \(\matr{H}\gets\distlin_1^{n,0}\), \(\advD_2\) perfectly simulates \(\sfGame_0\), and when \(\matr{H}\gets\distlin_1^{n,j^*}\), \(\advD_2\) perfectly simulates \(\sfGame_1\), which concludes the proof. 
\end{proof}

\begin{lemma} There exists an adversary \(\advB_\sfbits\) against \(\Pi_\sfbits\) such that
\(\Pr\left[ \mathsf{Game}_2(\advA)=1\right]\geq\dfrac{2}{\setsize }(\Pr\left[\mathsf{Game}_3(\advA)=1\right]+\adv_{\Pi_\sfbits}(\advB_\sfbits)).\)
\end{lemma}

\begin{proof}  The probability that
 \(\mathsf{Game}_3(\advA)=1\) is the probability that  a) \(\mathsf{Game}_2(\advA)=1\) and
b) \((b_{j^*,1},\ldots,b_{j^*,m})\notin\bits^m\) or \((b_2\cdots b_m) \neq (b_{j^*,2}\cdots b_{j^*,m})\). If \((b_{j^*,1},\ldots,\allowbreak b_{j^*,m})\notin\bits^m\) we can build an adversary \(\advB_\sfbits\) against \(\Pi_\sfbits\) and thus, the probability that \((b_{j^*,1},\ldots,b_{j^*,m})\in\bits^m\) is less than \(\adv_{\Pi_\sfbits}(\advB_1)\). The view of adversary \(\advA\) is independent of \((b_{2}\cdots b_{m})\), while, if \(\mathsf{Game_2}(\advA)=1\) and \((b_{j^*,1},\ldots,b_{j^*,m})\in\bits^{m}\), then \((b_{j^*,2}\cdots b_{j^*,m})\in[\setsize /2]\). Thus, 
the probability that the event described in b) occurs conditioned on \(\mathsf{Game_0}(\advA)=1\) and \((b_{j^*,1},\ldots,b_{j^*,m})\in\bits^{m}\), is greater than or equal to \(2/\setsize \) and the lemma follows.
\end{proof}

\begin{lemma} There exists a \(\distlin_1\)-\(\mddh_{\GG_1}\) adversary \(\advD_1\) such that
\(|\Pr\left[\mathsf{Game}_{3}(\advA)=1\right]\allowbreak-\Pr\left[\mathsf{Game}_{4}(\advA)=1\right]|\) $\leq
    \mathsf{Adv}_{\distlin_1,\GG_1}(\advD_1).$
\label{lemma:bits2}
\end{lemma}

\begin{proof}
We construct an adversary \(\advD_1\) that receives 
a challenge \(([\vecb{a}]_1,[\vecb{u}]_1)\) of the 
\(\distlin_1\)-\(\mddh_{\GG_1}\) Assumption. From this challenge, \(\advD_1\) defines for each \(\ell\in [m]\) the matrix  \([\matr{G}^\ell]_1\) as the matrix whose  \((j^*-1)\setsize /2^\ell+(b_{\ell+1}\cdots b_m)\) th column is \([\vecb{u}]_1\), and the rest of the columns are random vectors in the image of \([\vecb{a}]_1\). 
Obviously, when \([\vecb{u}]_1\) is sampled from 
the image of \([\vecb{a}]_1\), \([\matr{G}^\ell]_1\) follows the distribution \(\distlin_1^{n\setsize /2^\ell,0}\), while if \([\vecb{u}]_1\) is a uniform element of \(\GG^2_1\), \([\matr{G}^\ell]_1\) follows the distribution \(\distlin_1^{n\setsize /2^\ell,(j^*-1)\setsize /2^\ell+(b_{\ell+1}\cdots b_m)}\). 
 
The rest of the elements of the CRS are honestly computed. When \([\vecb{u}]_1\) is sampled from the image of \([\matr{a}]_1\), \(\advD_1\) perfectly simulates \(\sfGame_3\), and when \([\vecb{u}]_1\) is uniform, \(\advD_1\) perfectly simulates \(\sfGame_4\), which concludes the proof. 
\end{proof}


\begin{lemma}
There exist adversaries \(\advB_\sfcom\), against the strong soundness of \(\Pi_\sfcom\), \(\advB_\sfsum\), against the soundness of \(\Pi_\sfsum\), and an adversary \(\advB_\mathsf{lin}\) against the soundness of \(\Pi_\mathsf{lin}\), such that \(\Pr[\sfGame_4(\advA)=1]\leq 4/q+ \adv_{\Pi_\sfcom}(\advB_\sfcom)+m\adv_{\Pi_\sfsum}(\advB_\sfsum)+m\adv_{\Pi_\mathsf{lin}}(\advB_\mathsf{lin})\).
\end{lemma}
\begin{proof}
With probability \(1-4/q\), \(\{\vecb{g}_{j^*,(b_{\ell+1\cdots b_m})}^\ell,\vecb{g}_{n\setsize /2^\ell+1}^\ell\}\), \(\ell\in [m]\), and \(\{\vecb{h}_{i^*},\allowbreak \vecb{h}_{m+1}\}\) are bases of \(\Z_q^2\),
and, for each \(\ell\in [m],\mu\in\{1,2\}\), we can define \(\tilde{s}^\ell,\tilde{s}^{\ell-1}_\mu,\tilde{r}_\ell,\tilde{r}_{\mu,\ell},b_{j^*,\ell},\tilde{t}_\ell\) as the unique coefficients in \(\Z_q\) such that \(\vecb{c}_\ell=\allowbreak \tilde{s}^\ell\vecb{g}_{j^*,(b_{\ell+1}\cdots b_m)}^\ell + \tilde{r}_\ell \vecb{g}_{n\setsize /2^\ell+1}^\ell, \vecb{c}_{\ell,\mu}=\tilde{s}^{\ell-1}_\mu\vecb{g}_{j^*,(b_{\ell+1}\cdots b_m)}^\ell + \tilde{r}_{\mu,\ell} \vecb{g}_{n\setsize /2^\ell+1}^\ell,\) and \(\vecb{d}_\ell= b_{j^*,\ell} \vecb{h}_{j^*} + \tilde{t}_\ell \vecb{h}_{n+1}\).

Recall that if \(\sfGame_4(\advA)=1\) then \(x_{j^*}\notin S\). The adversary can win in \(\sfGame_4\) if one of the following events happen:
\begin{description}
\item[\(E_1\):] the adversary breaks soundness of \(\Pi_\sfcom\) and \(x_{j^*}\neq \tilde{s}^m\),
\item[\(E_2\):] the adversary breaks one of the \(m\)  instances of \(\Pi_\sfsum\) and \(\matr{\Theta}_\ell+\matr{\Pi}_\ell\notin\Span(\mathcal{C}_\ell)\),
\item[\(E_3\):] the adversary breaks one of the \(m\) instances of \(\Pi_\sflin\) and \((\vecb{c}_{\ell},\vecb{c}_{\ell+1,1},\vecb{c}_{\ell+1,2})\notin\Span(\matr{G}_\mathsf{split}^\ell)\),
\item[\(E_4\):] neither of \(E_1\),\(E_2\), or \(E_3\) happens, but \(x_{j^*}\notin S\) anyway.
\end{description}
By the law of total probabilities, \(\Pr[\sfGame_4(\advA)=1]\leq 4/q+\Pr[E_1]+\Pr[E_2]+\Pr[E_3]+\Pr[E_4]\), and is not hard to see that there exist adversaries \(\advB_\sfcom,\advB_\sfsum,\advB_\mathsf{lin}\) such that \(\Pr[E_1]=\adv_{\Pi_\sfcom}(\advB_\sfcom),\Pr[E_2]=m\adv_{\Pi_\sfsum}(\advB_\sfsum),\) and \(\Pr[E_3]=m\adv_{\Pi_\mathsf{lin}}(\advB_\mathsf{lin})\). Below we will show that \(\Pr[E_4]=0\) (using the same argument used in the non-aggregated case).

We prove by induction on \(\ell\) that \(\tilde{s}^\ell=s_{(b_1\cdots b_m)}\), where \(b_1:=b_{j^*,1}\). If this is the case, the fact that \(\neg E_1\) implies that \(x_{j^*}=\tilde{s}^m=s_{(b_1\cdots b_m)}\in S\) and we are ready. In the base case, if we multiply equation (\ref{eq-alog-5}) on the right by a vector \(\vecb{k}\) such that \(\vecb{h}_j^\top\vecb{k}=1\) if \(j=j^*\) and \(0\) if not (which exists since \(\{\vecb{h}_{j^*},\vecb{h}_{n+1}\}\) is a basis of \(\Z_q^2\)), together with the fact that \(\matr{\Theta}_1+\matr{\Pi}_1\in\Span(\mathcal{C}_1)\), and the fact that \(\vecb{c}_{1,1}=s_{0b_{2}\cdots b_{m}} \vecb{g}_{j^*,(b_{2}\cdots b_{m})}^1\) and \(\vecb{c}_{1,2}=s_{1b_{2}\cdots b_{m}}\vecb{g}_{j^*,(b_{2}\cdots b_{m})}^1\) implies that 
\begin{align*}
\vecb{c}_1 &= (1-b_{1})s_{(0b_{2}\cdots b_{m})} \vecb{g}_{j^*,(b_{2}\cdots b_{m})}^1+b_{1}s_{(1b_{2}\cdots b_{m})}\vecb{g}_{j^*,(b_{2}\cdots b_{m})}+\tilde{r}_1\vecb{g}_{n\setsize /2+1}^1\\
&=s_{(b_{1}\cdots b_{m})}\vecb{g}_{1,(b_{2}\cdots b_{m})}+\tilde{r}_1\vecb{g}_{n\setsize /2+1}^1.
\end{align*}

In the inductive case we assume that \(\vecb{c}_{\ell-1}=s_{(b_1\cdots b_m)}\vecb{g}_{j^*,(b_\ell\cdots b_m)}^{\ell-1}+\tilde{r}_{\ell-1}\vecb{g}_{n\setsize /2^{\ell-1}+1}^{\ell-1}\). Since \(\vecb{g}_{j^*,(b_\ell\cdots b_m)}^{\ell-1}\) is linearly independent from the rest of vectors in \(ck_{\ell-1}\), any solution to equation
\[
\begin{pmatrix}\vecb{c}_{\ell-1}\\\vecb{c}_{\ell,1}\\\vecb{c}_{\ell,2}\end{pmatrix}=\matr{G}^{\ell-1}_{\mathsf{split}}\vecb{w}
\]
 is equal to \(s_{(b_1\cdots b_m)}\) at position \((b_\ell \cdots b_m)\). An analysis of the two cases \(b_\ell=0\) or \(b_\ell=1\) shows that \(\vecb{c}_{\ell,b_\ell+1}=s_{(b_1\cdots b_m)}\vecb{g}_{j^*,(b_{\ell+1}\cdots b_m)}^\ell+\tilde{r}_{\ell,b_i+1}\vecb{g}_{n\setsize /2^\ell+1}^\ell\). Finally, equation (\ref{eq-alog-5}) implies that \(\vecb{c}_\ell=s_{(b_1\cdots b_m)}\vecb{g}_{j^*,(b_{\ell+1}\cdots b_m)}^\ell+\tilde{r}_\ell\vecb{g}_{n\setsize /2^\ell+1}^\ell\).
\end{proof}

\subsubsection{Perfect Zero-Knowledge}
Note that the vector the vectors \([\vecb{c}_\ell],[\vecb{c}_{\ell,1}]_1,[\vecb{c}_{\ell,2}]_1,[\vecb{d}_\ell]_2\) and matrices \([\matr{\Theta}_\ell]_1,[\matr{\Pi}_\ell]_2\), \(1\leq\ell\leq m\), output by the prover and the simulator are, respectively, uniform vectors and uniform matrices conditioned on satisfying equation \ref{eq-alog-5}. This follows from the fact that \(ck',ck_1,\ldots,ck_\ell\) are all perfectly hiding commitment keys and that \([\matr{\Theta}_\ell]_1,[\matr{\Pi}_\ell]_1\) are the unique solutions of equation (\ref{eq-alog-5}) modulo the random choice of \(\matr{R}_\ell\). Finally, the rest of the proof follows from Zero-Knowledge of \(\Pi_\sfcom,\Pi_\sfbits,\Pi_\sfsum,\) and \(\Pi_\mathsf{lin}\).

\subsection{The case \(S\subset\GG_1\)} \label{sec:improved-aZKSMP-group-case}
We briefly justify that the case \(S\subset\GG_1\) follows directly from the case \(S\subset\Z_q\) when \(S\) is a fixed witness samplable set. That is, there is a fixed set $S$ for each CRS, and there is an efficient algorithm that samples \(s_1,\ldots,s_{\setsize }\in\Z_q\) such that \(S=\{[s_1]_1,\ldots,[s_{\setsize }]_1\}\). %Note that this is the same case of Section~\ref{sec:bits-applications} where the CRS depends on set.

The reason why is not clear how to compute proofs in this setting is that it requires to compute values of the type \([\vecb{s}_i\vecb{k}]_1\), where \([\vecb{k}]_\mu\), \(\mu\in\{1,2\}\), is a vector from one of the commitment keys. The solution is straightforward: use \(s_1,\ldots,s_{\setsize }\) to compute these values and add them to the CRS (with the consequent CRS growth). Therefore, the new CRS contains also:
\begin{align*}
&[s_i\vecb{g}_{j,k}^\ell]_1 \text{ for } i,j\in [n], \ell\in [m], k\in[\setsize /2^\ell]\\
& s_i([\matr{C}^\ell_{j,k}]_1,[\matr{D}_{j,k}^\ell]_2) \text{ for } i,k\in [n], \ell\in [m], j\in [n\setsize /2^\ell].
\end{align*}

\subsection{Application: Theoretical \(\Theta(\log n)\) Ring Signature} \label{sec:log-ring-signature}

In this section we will describe how the improved aZKSMP can be used to obtain a \emph{theoretical} Ring Signature with signature size \(\Theta(\log n)\), where \(n\) is the size of the ring, in the standard model (i.e. without \emph{Random Oracles} nor \emph{Non-Falsifiable Assumptions}). In other words we show that there exist Set-Membership proofs of size \(\Theta(\log \setsize )\) even when \(S\subset \GG_1\) is not fixed (that is, prove membership in $\Lang_{ck,\mathsf{set}}^n\subset\GG_s^n$),\footnote{It seems that in the aggregated case this is also true. However, we leave this as an open problem.} and from this proof is direct to construct a Ring Signature using the techniques of Chandran et al.~\cite{ICALP:ChaGroSah07}.

We say that our construction is theoretical because, although the asymptotic signature size is \(\Theta(\log n)\), we use general results of NP-completeness and thus the ``real'' signature size is \(\Theta(\log n)+\mathsf{poly}(\lambda)\), where \(\lambda\) is the security parameter. Nonetheless, our result should be interpreted as a feasibility result and it poses the interesting question of whether the \(\mathsf{poly}(\lambda)\) part can be reduced to a practical value.

Lets see in a little more detail what is hidden in the asymptotics. When working on bilinear groups, the size of the proof is usually measured in number of group elements, and thus, if the proof is of size $f(n)$ groups elements its size in bits is $|\GG_s|f(n)$. Since $|\GG_s|$ is a linear function of the security parameter (and in practice of the order of one kilobit for $\lambda=128$) it is always ignored. In our case our proof additionally adds a constant number of group elements, with respect to $n$, but for which we only know that is upper bounded by some polynomial of $\lambda$. Therefore, although this part of the proof is independent of $n$, it is misleading to ignore its contribution to the total proof size.
 
We define an encoding function \(\mathcal{E}:\GG_1\cup\GG_2\to\bits^\ell\), where \(\ell=\mathsf{poly}(\lambda)\), which translates group elements to their natural bit encoding. Given a ring \(R=\{[vk_1]_1,\ldots,[vk_n]_1\}\) and \([vk]\in R\), we commit to \(\vecb{x}:=\mathcal{E}([vk]_1)\) using GS commitments and show that \(\mathcal{E}([vk]_1)\in\mathcal{E}(R)\), bit-by-bit, using the improved aZKSMP for \(S\subset \Z_q\). Let \([\vecb{c}]_1:=\GS.\Com_{ck}(\vecb{x}^\top;\matr{R}^\top)=([\vecb{c}_1]||\cdots||[\vecb{c}_\ell])\in\GG_1^{2\times \ell}\) and compute \([\vecb{d}]_1:=\GS.\Com_{ck}([vk]_1;(w_1,w_2)^\top)\), we would like to show that \(\mathcal{E}([vk]_1)=\vecb{x}\).

Given \(\vecb{x}\in\bits^\ell\), there exists a circuit \(C(\vecb{x},\vecb{w}_1,\vecb{w}_2,\vecb{y})\) that interprets \(\vecb{x},\vecb{w}_1,\vecb{w}_2\) as  elements \([x]_1,w_1,w_2\) of \(\GG_1,\Z_q,\Z_q\), respectively, and \(\vecb{y}\) as an element \([\vecb{d}]_1\) of \(\GG_1^2\), computes the bit-string
\begin{align*}
\vecb{s}:=
    &C_{\GG_1,-}(\\
        &\quad C_{\GG_1,-}(\\
            &\qquad C_{\GG_1,-}\left(
                \vecb{y},
                \mathcal{E}\left(
                        ({[x]_1},{[0]_1})^\top\right)\right),\\
            &\qquad C_{\GG_1,\cdot}(
                        \vecb{w}_1,
                        \mathcal{E}([\vecb{u}_1]_1)),\\
        &\quad C_{\GG_1,\cdot}(
                    \vecb{w}_2,
                    \mathcal{E}([\vecb{u}_2]_1)),
\end{align*}
where the circuit $C_{\GG_1,-}:\bits^{2\ell}\to\bits^\ell$ computes the subtraction (inverse and addition computation) of two elements of $\GG_1$, and the circuit $C_{\GG_1,\cdot}:\bits^{\log q+\ell}\to\bits^\ell$ computes the multiplication of an element from $\GG_1$ and an integer in $\Z_q$, and where \(([\vecb{u}_1]||[\vecb{u}_2]_1)=ck\). That is, $C$ is computing an encoding of $[\vecb{d}]_1-([x]_1,[0]_1)^\top-w_1[\vecb{u}]_1-w_2[\vecb{u}_2]$. Finally, $C$ returns 1 iff \(\vecb{s}=\mathcal{E}([0]_1)\). Using the NIZK proof system for Circuit Satisfiability of Groth et al.~\cite{EC:GroOstSah06} we can prove this statement with a proof of size \(\Theta(|C|)=\mathsf{poly}(\lambda)\), because \(|C|\) only depends on \(q=\poly(\lambda)\) and \(\ell=\poly(\lambda)\).

We conclude that we can prove that \([vk]_1\in R\) with a proof of size \(\Theta(\log n +\poly(\lambda))=\Theta(\log n)\), and thus we can construct a ring signature with signature size \(\Theta(\log n)\)
